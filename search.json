[
  {
    "objectID": "06_ethics_and_wrapup.html",
    "href": "06_ethics_and_wrapup.html",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "",
    "text": "This final notebook is fully theoretical and serves as the reflective conclusion of the LLM in Research workshop.\nBy now, participants have experimented with literature summarisation, retrieval-augmented generation (RAG), and code generation.\nHere, we step back and discuss how to use these capabilities responsibly in academic and research settings.",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "06_ethics_and_wrapup.html#why-ethics-matter-in-ai-research",
    "href": "06_ethics_and_wrapup.html#why-ethics-matter-in-ai-research",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "üß≠ Why Ethics Matter in AI Research",
    "text": "üß≠ Why Ethics Matter in AI Research\nLarge Language Models (LLMs) are not merely tools ‚Äî they shape how research is written, cited, and communicated.\nEthical use ensures that our work remains reproducible, transparent, and trustworthy.\n\nReproducibility: others should be able to verify what the model produced.\nTransparency: readers must know when AI was used.\nAccountability: responsibility stays with the human researcher, not the AI.\n\nEven small ethical lapses ‚Äî unverified summaries, missing citations, or hidden AI contributions ‚Äî can propagate misinformation through the scholarly record.",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "06_ethics_and_wrapup.html#hallucination-and-fabrication",
    "href": "06_ethics_and_wrapup.html#hallucination-and-fabrication",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "üí¨ Hallucination and Fabrication",
    "text": "üí¨ Hallucination and Fabrication\nHallucination means that an LLM produces text that sounds plausible but is not factually true.\nIt happens because the model predicts likely words, not verified facts.\n\nCommon manifestations:\n\nInvented citations (‚ÄúSmith et al., 2017‚Äù that never existed)\nConfident but false claims (‚ÄúThis study showed quantum teleportation of viruses‚Äù)\nMisquoted statistics or data sources\n\n\n\nWhy it happens:\n\nThe model has no built-in access to real-time databases.\nIt interpolates between known facts to fill gaps.\nSampling randomness (temperature) can increase hallucination frequency.\n\n\n\nMitigation strategies:\n\nCross-check every factual claim.\nAsk for sources or DOIs explicitly.\nUse RAG workflows (as in Notebook 04) to ground responses in retrieved evidence.",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "06_ethics_and_wrapup.html#bias-in-language-models",
    "href": "06_ethics_and_wrapup.html#bias-in-language-models",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "‚öñÔ∏è Bias in Language Models",
    "text": "‚öñÔ∏è Bias in Language Models\nLLMs learn from large-scale human text corpora and inherit human biases ‚Äî social, geographic, institutional, and ideological.\n\nTypes of bias\n\n\n\n\n\n\n\n\nType\nExample\nPossible Consequence\n\n\n\n\nGender bias\n‚ÄúThe nurse‚Ä¶ she‚Äù; ‚ÄúThe engineer‚Ä¶ he‚Äù\nReinforces stereotypes\n\n\nGeographic bias\nU.S.-centric examples\nMarginalises local or Global South contexts\n\n\nInstitutional bias\nOver-representation of elite universities\nSkews perception of authority\n\n\nTopical bias\nFocus on trendy disciplines\nNeglects underrepresented fields\n\n\n\n\n\nReflection prompts\n\nDoes your prompt assume one kind of author, culture, or region?\nAre the model‚Äôs suggestions diverse and representative?\nHow could biased phrasing influence downstream analyses?",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "06_ethics_and_wrapup.html#academic-writing-and-integrity",
    "href": "06_ethics_and_wrapup.html#academic-writing-and-integrity",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "‚úçÔ∏è Academic Writing and Integrity",
    "text": "‚úçÔ∏è Academic Writing and Integrity\nLLMs can help researchers: - Rephrase complex sentences - Improve grammar and flow - Suggest structure or headings\nHowever, there are boundaries of ethical use.\n\n\n\n\n\n\n\n\n\nPractice\nExample\nSafe?\nComment\n\n\n\n\nParaphrasing your own draft for clarity\n‚ÄúRewrite this paragraph in academic tone.‚Äù\n‚úÖ\nKeep authorship transparent.\n\n\nSummarising literature you provide\n‚ÄúSummarise this abstract in 3 sentences.‚Äù\n‚úÖ\nVerify facts manually.\n\n\nGenerating original citations\n‚ÄúList 5 references on‚Ä¶‚Äù\n‚ùå\nMay produce hallucinated papers.\n\n\nCopying large model outputs into a manuscript\n‚Äì\n‚ö†Ô∏è\nRequires attribution (‚ÄúAs generated by an LLM‚Ä¶‚Äù).\n\n\n\nRule of thumb:\n&gt; AI tools can assist writing but cannot author scholarship.\nAlways acknowledge LLM assistance in the acknowledgements or methods section.",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "06_ethics_and_wrapup.html#reproducibility-and-documentation",
    "href": "06_ethics_and_wrapup.html#reproducibility-and-documentation",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "üß± Reproducibility and Documentation",
    "text": "üß± Reproducibility and Documentation\nA reproducible AI workflow records exact conditions under which results were produced.\n\nGood documentation includes:\n\nModel name and version (e.g., Llama-3.1-70B, Groq API, May 2025)\nPrompt text and parameters (temperature, max tokens)\nRetrieval corpus and date of access\nAPI source or endpoint\nAny local preprocessing code or filters\n\n\n\nExample documentation block:\n\n‚ÄúSummaries were generated using Groq‚Äôs Llama-3.1-70B model (API version 2025-05-02) with temperature=0.2.\nInput abstracts were retrieved from ArXiv on 2025-05-10 using the query ‚Äòquantum batteries‚Äô.‚Äù",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "06_ethics_and_wrapup.html#ethical-checklist-for-llm-use",
    "href": "06_ethics_and_wrapup.html#ethical-checklist-for-llm-use",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "üìú Ethical Checklist for LLM Use",
    "text": "üìú Ethical Checklist for LLM Use\n\n\n\nAspect\nExample\nSafe Usage\n\n\n\n\nCitation\n‚ÄúAs summarised by LLM, based on ArXiv data‚Äù\n‚úÖ\n\n\nFabrication\n‚ÄúThis study found‚Ä¶‚Äù (invented)\n‚ùå\n\n\nSensitive data\nUpload of patient or private data\n‚ùå\n\n\nAttribution\n‚ÄúGenerated draft reviewed by author‚Äù\n‚úÖ\n\n\nConfidentiality\nSubmitting unpublished manuscripts\n‚ö†Ô∏è\n\n\nTransparency\n‚ÄúEdited for clarity using an LLM tool‚Äù\n‚úÖ\n\n\n\n\nInstitutional Guidelines\n\nMany universities now classify unacknowledged AI writing as academic misconduct.\nCheck your organisation‚Äôs policies (often listed under Research Integrity or Publication Ethics).",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "06_ethics_and_wrapup.html#final-reflection",
    "href": "06_ethics_and_wrapup.html#final-reflection",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "üß© Final Reflection",
    "text": "üß© Final Reflection\n\nWhat tasks will you responsibly delegate to an LLM?\n\nHow can you make your use of AI transparent and auditable?\n\nWould your workflow remain valid if the model were updated or replaced?",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "06_ethics_and_wrapup.html#summary",
    "href": "06_ethics_and_wrapup.html#summary",
    "title": "Responsible Use, Bias, and Academic Writing",
    "section": "‚úÖ Summary",
    "text": "‚úÖ Summary\n\nLLMs are probabilistic assistants, not authorities.\n\nBias and hallucination are systemic, not accidental.\n\nEthical use means attribution, verification, and documentation.\n\nTransparency builds trust ‚Äî in both research and AI.\n\n\n‚ÄúScience advances through transparency, not shortcuts.‚Äù\n\n\n\nEnd of Workshop\nCongratulations on completing the LLMs in Research series!\nYou now understand not only how to use LLMs for research but also how to do so responsibly and reproducibly.",
    "crumbs": [
      "06_ethics_and_wrapup"
    ]
  },
  {
    "objectID": "04_review_with_rag.html",
    "href": "04_review_with_rag.html",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "",
    "text": "What you‚Äôll do in this notebook\nIn the previous notebook, you curated and saved a top‚ÄëK set of papers to a CSV file (literature_corpus_top.csv).\nHere, you will:",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "04_review_with_rag.html#groq-api-settings-run-first",
    "href": "04_review_with_rag.html#groq-api-settings-run-first",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "0) Groq API Settings (Run first)",
    "text": "0) Groq API Settings (Run first)\nPaste your Groq API key. This is not secure if you share the notebook‚Äîit‚Äôs fine for a workshop demo.\n\n# --- Groq API Settings ---\nimport os\n\n# Paste your Groq API key below (between quotes).\n# NOTE: This is not a secure way of entering API keys if you share the notebook.\nos.environ[\"GROQ_API_KEY\"] = \"\"  # &lt;-- replace with your key (e.g., \"gsk_...\")\nmodel = \"llama-3.3-70b-versatile\"  # Pick a model. See https://console.groq.com/docs/models\nos.environ[\"BASE_URL\"] = \"https://api.groq.com/openai/v1\"  # OpenAI-compatible API\nprint(\"Groq settings configured. Remember to paste your API key!\")    \n\nGroq settings configured. Remember to paste your API key!",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "04_review_with_rag.html#create-the-client-and-the-chat-function",
    "href": "04_review_with_rag.html#create-the-client-and-the-chat-function",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "1) Create the client and the chat() function",
    "text": "1) Create the client and the chat() function\nWe use a single helper function chat() to talk to the model.\nTwo convenience helpers manage the conversation memory:\n\nset_system(text): sets the system prompt and resets the history.\n\nclear_chat(): clears history entirely.\n\n\nTip: Resetting the chat between tasks keeps context clean and results reproducible.\n\n\n# --- Create the OpenAI-compatible client + chat() helper ---\nfrom openai import OpenAI\n\nchat_history = []  # running memory for the current conversation\n\nclient = OpenAI(\n    api_key=os.environ[\"GROQ_API_KEY\"],\n    base_url=os.environ[\"BASE_URL\"],\n)\n\ndef set_system(prompt: str):\n    \"\"\"Reset chat history to a single system message.\"\"\"\n    global chat_history\n    chat_history = [{\"role\": \"system\", \"content\": prompt}]\n    return chat_history\n\ndef clear_chat():\n    \"\"\"Clear all chat history.\"\"\"\n    global chat_history\n    chat_history = []\n    return chat_history\n\ndef chat(user_input, temperature: float = 0.2, max_turns: int = 8):\n    \"\"\"Send one user turn and get a reply, preserving context.\n    - Keeps system prompt + last `max_turns` user/assistant messages.\n    \"\"\"\n    global chat_history\n    chat_history.append({\"role\": \"user\", \"content\": user_input})\n\n    # Keep only the most recent `max_turns` pairs to control context size\n    system = chat_history[:1]\n    recent = chat_history[-(max_turns*2):] if len(chat_history) &gt; 1 else []\n    window = system + recent\n\n    resp = client.chat.completions.create(\n        model=model,\n        messages=window,\n        temperature=temperature,\n    )\n    reply = resp.choices[0].message.content\n    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n    return reply\n\nprint(\"Testing API ...\")\nprint()\nprint(\"User:\")\nprint(\"Hello LLM!\")\nprint(\"LLM:\")\nprint(chat(\"Hello LLM!\"))\nprint()\nprint(\"Client ready. Use chat('...'), set_system('...'), clear_chat().\")\n\nTesting API ...\n\nUser:\nHello LLM!\nLLM:\nHello! It's nice to meet you. Is there something I can help you with or would you like to chat?\n\nClient ready. Use chat('...'), set_system('...'), clear_chat().",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "04_review_with_rag.html#load-the-curated-corpus-topk",
    "href": "04_review_with_rag.html#load-the-curated-corpus-topk",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "2) Load the curated corpus (top‚ÄëK)",
    "text": "2) Load the curated corpus (top‚ÄëK)\nIn Notebook 03, you created literature_corpus_top.csv‚Äîa curated set of the most relevant papers.\nWe load it here and briefly inspect the columns. You can open the CSV later in Excel if you like.\n\nImportant: We will use every row in this CSV (no further filtering here), because this file already represents the top‚ÄëK selection.\n\n\nimport pandas as pd\nfrom pathlib import Path\n\nDATA_DIR = Path(\"literature_data\")\nCORPUS_CSV = DATA_DIR / \"literature_corpus_top.csv\"\nassert CORPUS_CSV.exists(), \"Could not find literature_corpus_top.csv. Run Notebook 03 first.\"\n\ncorpus = pd.read_csv(CORPUS_CSV)\nprint(f\"Loaded corpus with {len(corpus)} rows.\")\ncorpus.head(3)\n\nLoaded corpus with 3 rows.\n\n\n\n\n\n\n\n\n\ntitle\nsummary\npublished\nlink\npdf\nauthors\nsummary_llm\nstructured\npdf_file\ncrude_text\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\n2024-05-06\nNaN\nhttp://arxiv.org/pdf/2405.03093v1\nTinggui Zhang, Hong Yang, Shao-Ming Fei\nThis study explores methods to enhance the cap...\n{'methodology': 'Local projective measurements...\n2405.03093v1.pdf\narXiv:2405.03093v1 [quant-ph] 6 May 2024\\nLo...\n\n\n1\nOptimizing quantum battery performance by redu...\nQuantum batteries have emerged as promising de...\n2025-05-12\nNaN\nhttp://arxiv.org/pdf/2505.08029v1\nRohit Kumar Shukla, Rajiv Kumar, Ujjwal Sen, S...\nResearchers investigated the dynamics of quant...\n{'methodology': 'Investigating interplay betwe...\n2505.08029v1.pdf\narXiv:2505.08029v1 [quant-ph] 12 May 2025\\nO...\n\n\n2\nEfficient charging of multiple open quantum ba...\nWe explore a protocol that efficiently charges...\n2024-10-25\nNaN\nhttp://arxiv.org/pdf/2410.19303v1\nJosephine Dias, Hui Wang, Kae Nemoto, Franco N...\nThis study aims to develop an efficient protoc...\n{'methodology': 'protocol using collective cou...\n2410.19303v1.pdf\nEfficient charging of multiple open quantum ba...\n\n\n\n\n\n\n\nWhat are these columns?\n- title: paper title\n- authors: authors (string)\n- published: publication date (from arXiv)\n- pdf: direct PDF link (we will cite this in the review)\n- link: arXiv HTML page (fallback if PDF is missing)\n- summary / summary_llm: abstract and/or LLM summary\n- crude_text: optional partial text extracted from PDF in the previous notebook\nIf some of these are missing, don‚Äôt worry‚Äîthis notebook still works with what you have.",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "04_review_with_rag.html#ask-a-research-question",
    "href": "04_review_with_rag.html#ask-a-research-question",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "3) Ask a research question",
    "text": "3) Ask a research question\nA clear question focuses the search and helps the model write a coherent review.\nYou can (and should) edit this to your topic of interest.\nYou can also pick keywords and only work on papers that contain at least one keywrod.\n\n# üëâ Edit this question to match your topic.\nresearch_question = \"How do local projective measurements influence the charging capacity of quantum batteries?\"\nkeywords = [\"quantum battery\", \"measurement\", \"projective\", \"capacity\", \"charging\"]\n\n\nWhy this matters: A good question anchors both your manual exploration (keyword checks) and the model‚Äôs synthesis.",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "04_review_with_rag.html#keyword-search-quick-evaluation-exploration",
    "href": "04_review_with_rag.html#keyword-search-quick-evaluation-exploration",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "4) Keyword search (quick evaluation & exploration)",
    "text": "4) Keyword search (quick evaluation & exploration)\nBefore synthesising a review, it‚Äôs useful to quickly scan which papers mention key terms from the question.\nThis is not semantic search‚Äîit‚Äôs a simple, transparent way to build intuition.\nWhat we‚Äôll do: 1. Choose a small list of keywords (derived from the question).\n2. Search each paper‚Äôs summary (or summary_llm / crude_text if summary is missing).\n3. Display papers that mention at least one keyword.\n\n# Choose simple keywords (edit freely)\n# Get all text from the crude_text column (empty string if missing)\ntext_series = corpus[\"crude_text\"].fillna(\"\").astype(str).str.lower()\n\n# Check whether each text contains any of the keywords\nmask = text_series.apply(lambda txt: any(k in txt for k in keywords))\n\n# Keep only rows that contain at least one keyword\nkeyword_hits = corpus[mask].copy()\n\nkeyword_hits.head(10)\n\n\n\n\n\n\n\n\ntitle\nsummary\npublished\nlink\npdf\nauthors\nsummary_llm\nstructured\npdf_file\ncrude_text\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\n2024-05-06\nNaN\nhttp://arxiv.org/pdf/2405.03093v1\nTinggui Zhang, Hong Yang, Shao-Ming Fei\nThis study explores methods to enhance the cap...\n{'methodology': 'Local projective measurements...\n2405.03093v1.pdf\narXiv:2405.03093v1 [quant-ph] 6 May 2024\\nLo...\n\n\n1\nOptimizing quantum battery performance by redu...\nQuantum batteries have emerged as promising de...\n2025-05-12\nNaN\nhttp://arxiv.org/pdf/2505.08029v1\nRohit Kumar Shukla, Rajiv Kumar, Ujjwal Sen, S...\nResearchers investigated the dynamics of quant...\n{'methodology': 'Investigating interplay betwe...\n2505.08029v1.pdf\narXiv:2505.08029v1 [quant-ph] 12 May 2025\\nO...\n\n\n2\nEfficient charging of multiple open quantum ba...\nWe explore a protocol that efficiently charges...\n2024-10-25\nNaN\nhttp://arxiv.org/pdf/2410.19303v1\nJosephine Dias, Hui Wang, Kae Nemoto, Franco N...\nThis study aims to develop an efficient protoc...\n{'methodology': 'protocol using collective cou...\n2410.19303v1.pdf\nEfficient charging of multiple open quantum ba...\n\n\n\n\n\n\n\nReading the results: Hit counts provide a rough, explainable signal.\nIf you see very few hits, consider broadening your keywords or checking a different text column (e.g., crude_text).",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "04_review_with_rag.html#write-a-twoparagraph-literature-review-with-real-links",
    "href": "04_review_with_rag.html#write-a-twoparagraph-literature-review-with-real-links",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "5) Write a two‚Äëparagraph literature review (with real links)",
    "text": "5) Write a two‚Äëparagraph literature review (with real links)\nWe now ask the LLM to write a two‚Äëparagraph literature review that directly answers our research question.\nTo keep the output verifiable, we ask the model to cite papers by linking to their PDF (from the pdf column).\nHow we make it reliable: - We present the model with the full table of candidate papers (already curated top‚ÄëK).\n- We give a clear instruction to base the review only on these papers.\n- We explicitly ask for citations using the pdf links in parentheses.\n\n# We build a compact textual view of the corpus that the model can read.\n# Keep the table short enough to fit into the prompt. If your corpus is long,\n# consider slicing columns or truncating summaries.\n\nsubset_cols = [c for c in [\"title\",\"summary\",\"pdf\"] if c in corpus.columns]\ntable_for_prompt = corpus[subset_cols].fillna(\"\").copy()\n\n# Truncate long summaries to keep the prompt smaller and cheaper\ntable_for_prompt[\"summary\"] = table_for_prompt[\"summary\"].apply(lambda s: (s[:700] + \"‚Ä¶\") if isinstance(s, str) and len(s) &gt; 700 else s)\ntable_for_prompt\n\n\n\n\n\n\n\n\ntitle\nsummary\npdf\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\nhttp://arxiv.org/pdf/2405.03093v1\n\n\n1\nOptimizing quantum battery performance by redu...\nQuantum batteries have emerged as promising de...\nhttp://arxiv.org/pdf/2505.08029v1\n\n\n2\nEfficient charging of multiple open quantum ba...\nWe explore a protocol that efficiently charges...\nhttp://arxiv.org/pdf/2410.19303v1\n\n\n\n\n\n\n\n\n\nprompt = f\"\"\"    Write a coherent **two-paragraph literature review** answering the question below.\nUse **only** the papers provided. For each claim, cite at least one paper\nby adding the paper's **PDF link** in parentheses, e.g., (https://arxiv.org/pdf/XXXX).\n\n**Question:**\n{research_question}\n\n**Papers (title, summary, pdf):**\n{table_for_prompt.to_string(index=False)}\n\nRequirements:\n- Two paragraphs, formal academic tone\n- Factual, concise, and grounded in the provided papers\n- Each paragraph should contain at least one citation using the `pdf` link\n- Do not invent citations or links\n\"\"\"\n\nprompt\n\n\"    Write a coherent **two-paragraph literature review** answering the question below.\\nUse **only** the papers provided. For each claim, cite at least one paper\\nby adding the paper's **PDF link** in parentheses, e.g., (https://arxiv.org/pdf/XXXX).\\n\\n**Question:**\\nHow do local projective measurements influence the charging capacity of quantum batteries?\\n\\n**Papers (title, summary, pdf):**\\n                                                                                    title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       summary                               pdf\\n                           Local-projective-measurement-enhanced quantum battery capacity Quantum batteries have significant potential applications for future industry and daily life. The capacity is an important indicator for a battery. Methods to improve the capacity of quantum batteries are important. We consider quantum batteries given by bipartite quantum systems and study the enhancement of the battery capacity under local projective measurements on a subsystem of the quantum state. By using two-qubit Bell-diagonal states and X-type states as examples, we show that quantum battery capacity with respect to the whole system or a subsystem can be improved by local projective measurements. Our theoretical analysis will provide ideas for the experimental development of quantum b‚Ä¶ http://arxiv.org/pdf/2405.03093v1\\nOptimizing quantum battery performance by reducing battery influence in charging dynamics Quantum batteries have emerged as promising devices that work within the quantum regime and provide energy storage and power delivery. We investigate the interplay between the battery and charger Hamiltonians, with a particular focus on minimizing the battery s influence during the charging dynamics. To achieve this, we introduce a control parameter that allows us to suppress the battery s contribution during the charging dynamics. We explore various configurations, including a non-interacting many-body battery with an interacting many-body charger, an interacting battery with a non-interacting charger, and systems where both the battery and charger are interacting many-body systems. Our res‚Ä¶ http://arxiv.org/pdf/2505.08029v1\\n    Efficient charging of multiple open quantum batteries through dissipation and pumping                                                                   We explore a protocol that efficiently charges multiple open quantum batteries in parallel using a single charger. This protocol shows super-extensive charging through collective coupling of the charger and the battery to the same thermal reservoir. When applied to multiple quantum batteries, each coupled to different thermal reservoirs, the energy cannot be efficiently transferred from the charger to the battery via collective dissipation alone. We show that the counter-intuitive act of incorporating both dissipation and incoherent collective pumping on the charger enables efficient parallel charging of many quantum batteries. http://arxiv.org/pdf/2410.19303v1\\n\\nRequirements:\\n- Two paragraphs, formal academic tone\\n- Factual, concise, and grounded in the provided papers\\n- Each paragraph should contain at least one citation using the `pdf` link\\n- Do not invent citations or links\\n\"\n\n\n\n\nclear_chat()\nset_system(\"You are an academic assistant writing short literature reviews.\")\n\nreview_text = chat(prompt, temperature=0.3)\nprint(review_text)\n\nThe influence of local projective measurements on the charging capacity of quantum batteries has been a subject of interest in recent studies. Research has shown that local projective measurements can enhance the capacity of quantum batteries, particularly in bipartite quantum systems (http://arxiv.org/pdf/2405.03093v1). By applying local projective measurements on a subsystem of the quantum state, the battery capacity with respect to the whole system or a subsystem can be improved. This has been demonstrated using two-qubit Bell-diagonal states and X-type states as examples, highlighting the potential of local projective measurements in optimizing quantum battery performance (http://arxiv.org/pdf/2405.03093v1). Furthermore, the interplay between the battery and charger Hamiltonians has also been investigated, with a focus on minimizing the battery's influence during the charging dynamics (http://arxiv.org/pdf/2505.08029v1).\n\nThe optimization of quantum battery performance is a complex task, involving the manipulation of various parameters to achieve efficient charging. In addition to local projective measurements, other strategies have been proposed to enhance charging capacity. For instance, a protocol that utilizes dissipation and pumping to charge multiple open quantum batteries in parallel has been explored (http://arxiv.org/pdf/2410.19303v1). This approach enables super-extensive charging through collective coupling of the charger and the battery to the same thermal reservoir. Moreover, the incorporation of both dissipation and incoherent collective pumping on the charger has been shown to facilitate efficient parallel charging of many quantum batteries (http://arxiv.org/pdf/2410.19303v1). These findings highlight the importance of considering multiple factors, including local projective measurements and charging dynamics, to optimize the performance of quantum batteries (http://arxiv.org/pdf/2505.08029v1).\n\n\nTip: If you see missing or incorrect links, check your pdf column values.\nYou can also reduce the prompt size by limiting columns, or by shortening summaries more aggressively.",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "04_review_with_rag.html#save-the-generated-review-optional-but-recommended",
    "href": "04_review_with_rag.html#save-the-generated-review-optional-but-recommended",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "6) Save the generated review (optional but recommended)",
    "text": "6) Save the generated review (optional but recommended)\nSaving the output makes it easy to share or iterate later.\n\nfrom pathlib import Path\nout_txt = Path(\"literature_data\") / \"mini_lit_review.txt\"\nwith open(out_txt, \"w\", encoding=\"utf-8\") as f:\n    f.write(review_text)\nprint(\"Saved review to:\", out_txt.resolve())\n\nSaved review to: C:\\code\\llm_tutorial\\literature_data\\mini_lit_review.txt",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "04_review_with_rag.html#beyond-this-notebook-methods-for-larger-corpora-theory-only",
    "href": "04_review_with_rag.html#beyond-this-notebook-methods-for-larger-corpora-theory-only",
    "title": "04 ‚Äî Writing a Mini Literature Review with RAG",
    "section": "7) Beyond this notebook ‚Äî methods for larger corpora (theory only)",
    "text": "7) Beyond this notebook ‚Äî methods for larger corpora (theory only)\nWhen the number of papers becomes large, we need methods that scale while keeping quality high.\nA. Embedding‚Äëbased retrieval and clustering\n- Convert each abstract/full text and your question into vector embeddings.\n- Use cosine similarity to retrieve the most relevant papers.\n- Cluster embeddings (e.g., with K‚ÄëMeans or HDBSCAN) to reveal themes or subtopics, then summarise per cluster.\nB. Hierarchical summarisation\n- Summarise small batches (or clusters) of papers first.\n- Then summarise those summaries to produce a clean, high‚Äëlevel narrative.\n- This divide‚Äëand‚Äëconquer approach scales to hundreds of papers.\nC. Hybrid RAG pipelines\n- Combine embeddings for retrieval (fast, consistent) with an LLM for synthesis (nuanced, fluent).\n- Ground the LLM in retrieved passages to reduce hallucinations, and always cite source papers.\nD. Multi‚Äëcriteria scoring\n- Define simple criteria (e.g., method novelty, data similarity, domain fit, practicality) and score each paper (1‚Äì5).\n- Take a weighted average to rank papers. This improves transparency and repeatability in reviews.\n\nThese ideas extend the simple approach in this notebook and are commonly used in systematic reviews and large‚Äëscale literature surveys.",
    "crumbs": [
      "04_review_with_rag"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html",
    "href": "02_theory_and_concepts.html",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "",
    "text": "This notebook introduces the conceptual foundations of Large Language Models (LLMs) in research contexts. Before working with APIs, it‚Äôs crucial to understand what LLMs are, what they can and cannot do, and how to use them responsibly.\nWe will cover: - What LLMs are and how they work - Strengths and weaknesses in research use - Basics of prompt engineering - Why hallucination occurs and how to detect it - Benefits and risks across use cases - Concept of Agentic AI - Running LLMs via API vs locally",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#what-is-a-large-language-model-llm",
    "href": "02_theory_and_concepts.html#what-is-a-large-language-model-llm",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "1. What Is a Large Language Model (LLM)?",
    "text": "1. What Is a Large Language Model (LLM)?\nAn LLM is a probabilistic text generator. It predicts the next word in a sequence based on all the previous words.\nFormally, it learns to estimate:\n\\[p(x_{t+1} \\mid x_{1:t}) = \\text{softmax}\\left(\\frac{z_i}{T}\\right)\\]\nwhere \\(z_i\\) are logits (raw scores), and \\(T\\) is temperature controlling randomness.\nKey ideas: - The model is not reasoning; it‚Äôs pattern matching. - It is trained on billions of text samples. - It does not know whether statements are true.\nüí° Analogy: LLMs complete text the way autocomplete finishes a sentence ‚Äî just on a massive scale.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#what-llms-are-good-for-and-what-they-are-not",
    "href": "02_theory_and_concepts.html#what-llms-are-good-for-and-what-they-are-not",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "2. What LLMs Are Good For ‚Äî and What They Are Not",
    "text": "2. What LLMs Are Good For ‚Äî and What They Are Not\n\n\n\n‚úÖ Good At\n‚ö†Ô∏è Not Good At\n\n\n\n\nSummarising academic text\nProducing verified facts\n\n\nParaphrasing and rewriting\nMathematical proofs or derivations\n\n\nExplaining code or methods\nStatistical inference without data\n\n\nGenerating boilerplate writing\nHandling private or sensitive data\n\n\nBrainstorming research ideas\nActing as a source of truth\n\n\n\nThink of an LLM as an assistant, not a co-author.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#prompt-engineering-essentials",
    "href": "02_theory_and_concepts.html#prompt-engineering-essentials",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "3. Prompt Engineering Essentials",
    "text": "3. Prompt Engineering Essentials\nPrompt engineering means crafting the input to shape the model‚Äôs response.\n\nExample\n‚ùå Bad: Explain machine learning.\n‚úÖ Better: In three sentences, explain machine learning to a biology PhD student unfamiliar with computer science.\n\n\nBest Practices\n\nBe specific about role, audience, and format.\nUse system messages to set tone or constraints.\nBreak complex queries into smaller sub-prompts.\nAsk for structured output (e.g., JSON, tables).\n\nLet‚Äôs illustrate how different prompt structures might be interpreted.\n\n# Demonstration: Prompt variety examples (no API calls)\n# This cell just prints examples and explanations of what makes prompts effective.\n\nexample_prompts = [\n    (\"Explain AI.\", \"Too vague ‚Äî model may produce generic output.\"),\n    (\"Explain Artificial Intelligence in two sentences for an interdisciplinary audience.\", \"Better ‚Äî specifies length and audience.\"),\n    (\"As a data scientist, summarise Artificial Intelligence focusing on statistical learning methods.\", \"Excellent ‚Äî adds role and context, leading to relevant focus.\")\n]\n\nfor text, comment in example_prompts:\n    print(f\"Prompt: {text}\\nComment: {comment}\\n{'-'*70}\")\n\nPrompt: Explain AI.\nComment: Too vague ‚Äî model may produce generic output.\n----------------------------------------------------------------------\nPrompt: Explain Artificial Intelligence in two sentences for an interdisciplinary audience.\nComment: Better ‚Äî specifies length and audience.\n----------------------------------------------------------------------\nPrompt: As a data scientist, summarise Artificial Intelligence focusing on statistical learning methods.\nComment: Excellent ‚Äî adds role and context, leading to relevant focus.\n----------------------------------------------------------------------\n\n\n\n\nReflection\n\nHow would you phrase prompts for your research area?\nWhat happens if your question is ambiguous or underspecified?\nHow might prompt reproducibility affect research transparency?",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#why-hallucination-happens",
    "href": "02_theory_and_concepts.html#why-hallucination-happens",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "4. Why Hallucination Happens",
    "text": "4. Why Hallucination Happens\nHallucination is when the model produces false but plausible information.\nCauses: 1. Models optimise for fluency, not truth. 2. They lack external knowledge verification. 3. They use patterns, not evidence.\nMitigations: - Use grounded prompts (e.g., with text context or retrieval). - Ask for sources and check them. - Rephrase prompts to encourage uncertainty awareness (e.g., ‚ÄúIf unsure, say so.‚Äù)\n\n# Simulating hallucination detection with a fabricated response\n# This code checks whether a response contains uncertainty words.\n\nresponse = \"Dr. Jane Quantum won the Nobel Prize in Quantum Psychology in 2024.\"\n\nuncertainty_markers = [\"might\", \"possibly\", \"may\", \"perhaps\", \"uncertain\"]\nuncertain = any(word in response.lower() for word in uncertainty_markers)\n\nif uncertain:\n    print(\"‚úÖ The statement expresses uncertainty.\")\nelse:\n    print(\"‚ö†Ô∏è This response shows *overconfidence* ‚Äî likely hallucination.\")\n\n‚ö†Ô∏è This response shows *overconfidence* ‚Äî likely hallucination.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#benefits-and-risks-in-research",
    "href": "02_theory_and_concepts.html#benefits-and-risks-in-research",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "5. Benefits and Risks in Research",
    "text": "5. Benefits and Risks in Research\n\n\n\n\n\n\n\n\nApplication\nBenefit\nRisk / Limitation\n\n\n\n\nLiterature summarisation\nSaves time, finds patterns\nHallucinated facts or missing nuance\n\n\nCoding help\nFaster prototyping\nWrong syntax or unsafe imports\n\n\nAcademic writing\nBetter grammar, flow\nStyle drift, plagiarism concerns\n\n\nBrainstorming ideas\nExpands creativity\nMay output unverified claims\n\n\nData cleaning\nQuick suggestions\nMay fabricate column names\n\n\n\nüß≠ Always cross-check LLM-generated outputs before citing or integrating into research.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#agentic-ai-concept-only",
    "href": "02_theory_and_concepts.html#agentic-ai-concept-only",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "6. Agentic AI (Concept Only)",
    "text": "6. Agentic AI (Concept Only)\nAgentic AI refers to models that can take initiative ‚Äî plan actions, call tools, and iteratively refine results.\nExamples: AutoGPT, LangChain Agents, ChatGPT with code or browsing.\nThey combine: - Planning (deciding what to do next) - Memory (recalling previous steps) - Tool use (e.g., running Python or querying databases)\n\nWhy it matters\n\nMoves from passive Q&A to autonomous workflows.\nRaises questions of accountability and control.\n\nüß© The RAG (Retrieval-Augmented Generation) notebook later in this series is a small step toward agentic systems.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#running-llms-via-api-vs-locally",
    "href": "02_theory_and_concepts.html#running-llms-via-api-vs-locally",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "7. Running LLMs via API vs Locally",
    "text": "7. Running LLMs via API vs Locally\n\nComparison\n\n\n\n\n\n\n\n\nApproach\nPros\nCons\n\n\n\n\nAPI (Groq, OpenAI)\nNo setup, scalable, always updated\nRequires internet, API cost\n\n\nLocal (Hugging Face, vLLM)\nFull control, offline\nNeeds high VRAM, complex setup\n\n\n\nBelow we estimate how much GPU memory is needed to run different models locally.\n\n# Estimate GPU VRAM requirement for hosting models locally\n# Rule of thumb: 1 billion parameters ‚âà 2 GB VRAM (16-bit precision)\n\ndef estimate_vram(params_billion, precision_bits=16):\n    \"\"\"Estimate GPU memory needed for model parameters.\"\"\"\n    bytes_per_param = precision_bits / 8\n    total_gb = (params_billion * 1e9 * bytes_per_param) / (1e9 * 1.024)\n    return round(total_gb, 1)\n\nmodels = {\"Llama-3 8B\": 8, \"Llama-3 70B\": 70, \"Mistral 7B\": 7}\n\nprint(\"Approximate VRAM needed (16-bit precision):\\n\")\nfor model, size in models.items():\n    print(f\"{model:15s}: {estimate_vram(size)} GB\")\n\nApproximate VRAM needed (16-bit precision):\n\nLlama-3 8B     : 15.6 GB\nLlama-3 70B    : 136.7 GB\nMistral 7B     : 13.7 GB\n\n\n‚û°Ô∏è A 70B model would require well over 140 GB of GPU VRAM, so APIs are currently the most practical solution for most researchers.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#pros-and-cons-summary",
    "href": "02_theory_and_concepts.html#pros-and-cons-summary",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "8. Pros and Cons Summary",
    "text": "8. Pros and Cons Summary\n\n\n\nAspect\nPros\nCons\n\n\n\n\nEase of use\nMinimal setup\nReliance on vendor uptime\n\n\nCost\nFree/cheap for small workloads\nExpensive at scale\n\n\nReproducibility\nControlled APIs\nModel updates may change outputs\n\n\nEthics\nAccessible to all\nPrivacy and bias concerns\n\n\n\nBalance practicality with reproducibility ‚Äî document all model versions and API calls when publishing results.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#reflection-1",
    "href": "02_theory_and_concepts.html#reflection-1",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "9. Reflection",
    "text": "9. Reflection\nQuestions for you: 1. Which tasks in your workflow could LLMs assist with? 2. What risks might arise from automation in your field? 3. How can you document LLM involvement transparently in your papers?\nWrite your reflections below as markdown cells.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "02_theory_and_concepts.html#summary",
    "href": "02_theory_and_concepts.html#summary",
    "title": "Theory and Concepts: Understanding LLMs Before You Trust Them",
    "section": "‚úÖ Summary",
    "text": "‚úÖ Summary\n\nLLMs predict words, not truths ‚Äî verification is essential.\nPrompt engineering is key to consistent behaviour.\nHallucinations are unavoidable but detectable.\nAgentic AI is emerging; RAG is its foundation.\nAPIs simplify use; local models give control but need hardware.\n\n‚û°Ô∏è Next, we‚Äôll use these concepts in practice to perform literature summarisation using Groq + Llama-3 70B.",
    "crumbs": [
      "02_theory_and_concepts"
    ]
  },
  {
    "objectID": "00_setup_guide.html",
    "href": "00_setup_guide.html",
    "title": "Large Language Models for Research -",
    "section": "",
    "text": "A workshop by QCIF\nhttps://www.qcif.edu.au/\nAuthor: Moji Ghadimi\nhttps://www.linkedin.com/in/moji-ghadimi/",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "00_setup_guide.html#install-python-recommended-version-3.10-or-newer",
    "href": "00_setup_guide.html#install-python-recommended-version-3.10-or-newer",
    "title": "Large Language Models for Research -",
    "section": "üêç 1. Install Python (Recommended: Version 3.10 or newer)",
    "text": "üêç 1. Install Python (Recommended: Version 3.10 or newer)\n\nWindows\n\nGo to the official Python website: https://www.python.org/downloads/\nDownload the latest Python 3.x installer.\nRun the installer and check the box that says:\n\n‚úÖ Add Python to PATH\n\nChoose Install Now and follow the prompts.\n\nTo verify installation, open Command Prompt (cmd) and type:\npython --version\nYou should see something like:\nPython 3.11.6\n\n\n\nmacOS / Linux\nMost systems come with Python preinstalled. You can check your version:\npython3 --version\nIf Python is not installed, install it using your system package manager:\nmacOS (Homebrew):\nbrew install python\nUbuntu / Debian:\nsudo apt update && sudo apt install python3 python3-pip -y",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "00_setup_guide.html#install-jupyterlab",
    "href": "00_setup_guide.html#install-jupyterlab",
    "title": "Large Language Models for Research -",
    "section": "üì¶ 2. Install jupyterlab",
    "text": "üì¶ 2. Install jupyterlab\nOnce Python is installed, you can install packages using pip (Python‚Äôs package manager).\nRun this command in your terminal or command prompt:\npip install jupyterlab\n\njupyterlab is used for running notebooks interactively.",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "00_setup_guide.html#download-notebooks",
    "href": "00_setup_guide.html#download-notebooks",
    "title": "Large Language Models for Research -",
    "section": "üì¶ 3. Download notebooks",
    "text": "üì¶ 3. Download notebooks\nDownload notebooks.zip from the left menu of workshop website and extract to your desired folder.",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "00_setup_guide.html#launch-jupyterlab",
    "href": "00_setup_guide.html#launch-jupyterlab",
    "title": "Large Language Models for Research -",
    "section": "üß† 4. Launch JupyterLab",
    "text": "üß† 4. Launch JupyterLab\nOpen terminal or command prompt and navigate to the folder containing your workshop notebooks (or navigate then open a terminal), then run:\npython -m jupyter lab\nThis will open a new tab in your default web browser with the JupyterLab interface.\nYou can then click on any notebook to open it.",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "00_setup_guide.html#running-on-hpc",
    "href": "00_setup_guide.html#running-on-hpc",
    "title": "Large Language Models for Research -",
    "section": "‚öôÔ∏è 5. Running on HPC",
    "text": "‚öôÔ∏è 5. Running on HPC\nIf you‚Äôre using a hosted JupyterLab instance on HPC infrastructure, Python and most dependencies are already installed. You typically only need to:\n\nOpen the web-based JupyterLab interface.\nLoad the correct Python environment (via module or dropdown).\ndownload and extract notebooks.zip from the left menu of the website.\nUpload notebooks to the HPC‚Äôs jupyter lab.\nRun 00_setup_guide.ipynb (this notebook).",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "00_setup_guide.html#install-required-python-packages",
    "href": "00_setup_guide.html#install-required-python-packages",
    "title": "Large Language Models for Research -",
    "section": "üì¶ 6. Install Required Python Packages",
    "text": "üì¶ 6. Install Required Python Packages\nIf the packages below are not installed uncomment (remove #) and run the cell below to install packages:\n\n# !pip install numpy pandas matplotlib openai requests pypdf \n\nNote if you are running this in a terminal you need to remove ‚Äú!‚Äù from teh start of the command. This will install:\n\nnumpy ‚Äì for handling arrays.\npandas ‚Äì for handling data.\nmatplotlib ‚Äì for plotting.\nopenai ‚Äì to connect to Groq or OpenAI-compatible APIs.\nrequests ‚Äì for fetching data from APIs.\npypdf ‚Äì for reading PDFs.\n\nTo verify installation, run the code below:\n\nimport importlib.metadata\n\npackages = [\"numpy\", \"pandas\", \"matplotlib\", \"openai\", \"requests\", \"pypdf\" ]\nfor pkg in packages:\n    try:\n        print(f\"{pkg}: {importlib.metadata.version(pkg)}\")\n    except importlib.metadata.PackageNotFoundError:\n        print(f\"{pkg}: not installed\")\n\nnumpy: 2.3.3\npandas: 2.3.3\nmatplotlib: 3.10.7\nopenai: 2.6.0\nrequests: 2.32.5\npypdf: 6.1.3",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "00_setup_guide.html#get-a-groq-api-key-to-access-a-llm-online",
    "href": "00_setup_guide.html#get-a-groq-api-key-to-access-a-llm-online",
    "title": "Large Language Models for Research -",
    "section": "‚öôÔ∏è 7: Get a Groq API key to access a llm online",
    "text": "‚öôÔ∏è 7: Get a Groq API key to access a llm online\n\nSign In to Your Groq Account. Go to https://console.groq.com/login.\nIf you already have an account, sign in.\n\nIf not, create a new account and complete the verification process.\n\nGenerate Your Groq API Key: 1. Navigate to the API Keys section from the left menu.\n2. Click Create API Key. 3. In the pop-up window, enter a descriptive name for your key (e.g., AI Content Labs) in the Display name for the key field.\n- This helps you easily identify the key later.\n4. Click Submit.\n5. Copy the displayed API key ‚Äî it will only be shown once.\n- Save it securely for future use.",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "00_setup_guide.html#summary",
    "href": "00_setup_guide.html#summary",
    "title": "Large Language Models for Research -",
    "section": "‚úÖ Summary",
    "text": "‚úÖ Summary\n\nInstall Python ‚â• 3.10\nUse pip to install required packages\nRun jupyter lab\nVerify everything by opening the example notebooks\nGet a Groq API key",
    "crumbs": [
      "00_setup_guide"
    ]
  },
  {
    "objectID": "01_introduction_llm.html",
    "href": "01_introduction_llm.html",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "",
    "text": "This notebook is the first module of a workshop on using Large Language Models (LLMs) in research workflows. It focuses on:\nWe adopt a text-only approach (no image/graph understanding) to ensure minimal setup and maximum reproducibility.\nBy the end of this notebook, you will be able to: 1. Configure a connection to the Groq API. 2. Send chat messages with the OpenAI-compatible client. 3. Control generation behaviour via temperature. 4. Maintain and reuse chat history for a continuing conversation.",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "01_introduction_llm.html#background-very-briefly",
    "href": "01_introduction_llm.html#background-very-briefly",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "Background (very briefly)",
    "text": "Background (very briefly)\nAn LLM is a probabilistic model over text. Given a sequence of tokens \\(x_{1:t}\\), it assigns probabilities to the next token \\(x_{t+1}\\). At inference, models sample from a distribution such as \\[p(x_{t+1}=i\\mid x_{1:t}) = \\mathrm{softmax}\\!\\left(\\frac{z_i}{T}\\right),\\] where \\(z_i\\) is the logit for token \\(i\\) and \\(T&gt;0\\) is the temperature. Lower \\(T\\) concentrates probability mass on high-logit tokens (more deterministic), while higher \\(T\\) spreads it out (more diverse). We will demonstrate this behaviour below.",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "01_introduction_llm.html#environment-setup",
    "href": "01_introduction_llm.html#environment-setup",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "1) Environment Setup",
    "text": "1) Environment Setup\nThis section prepares the Python environment. On QCIF‚Äôs HPC JupyterLab image, the required package (openai) should already be installed. If you‚Äôre running elsewhere and encounter an ImportError, uncomment the %pip install line.\nWhat this cell does: - (Optionally) installs the OpenAI Python client. - Imports the required modules. - Does not make any external calls yet.\n\n# If running outside the provided environment, uncomment the next line:\n# %pip install openai\nimport os\nfrom openai import OpenAI",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "01_introduction_llm.html#configure-api-connection-groq",
    "href": "01_introduction_llm.html#configure-api-connection-groq",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "2) Configure API Connection (Groq)",
    "text": "2) Configure API Connection (Groq)\nLLM APIs are stateless web services. We‚Äôll configure a client that speaks the OpenAI-compatible protocol, pointing it to Groq‚Äôs base URL.\nWhat you‚Äôll do in this cell: 1. Paste your Groq API key (created at https://console.groq.com). 2. Set the base URL for Groq‚Äôs OpenAI-compatible endpoint. 3. Instantiate the client.\nNotes: - Keep your API key private. In shared workshops, you can paste it, run this cell, and then clear the visible text. - You can also store keys in environment variables or use a .env file if preferred.\n\n# Paste your Groq API key below (between quotes). \n# Note this is not a secure way of entering API key because it is visible to everyone that sees your notebook.  \nos.environ[\"GROQ_API_KEY\"] = \"\"  # &lt;-- replace with your key.\nmodel = \"llama-3.3-70b-versatile\" # Select your model https://console.groq.com/docs/models\nos.environ[\"BASE_URL\"] = \"https://api.groq.com/openai/v1\" # Groq uses an OpenAI-compatible API surface; we just change the base URL.\n\n\n# Create the client\nclient = OpenAI(\n    api_key=os.environ[\"GROQ_API_KEY\"],\n    base_url=os.environ[\"BASE_URL\"],\n)\nprint(\"Groq client initialized!\")\n\nGroq client initialized!",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "01_introduction_llm.html#first-llm-call-hello-llm-llama-3-70b",
    "href": "01_introduction_llm.html#first-llm-call-hello-llm-llama-3-70b",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "3) First LLM Call ‚Äî ‚ÄúHello LLM‚Äù (Llama-3 70B)",
    "text": "3) First LLM Call ‚Äî ‚ÄúHello LLM‚Äù (Llama-3 70B)\nHere we send a single-turn prompt with minimal scaffolding. The API expects a list of messages, where each message has a role and content.\nRoles: - system: high-level instructions (tone, persona, formatting). - user: your question or instruction. - assistant: the model‚Äôs reply (the API returns this).\nWhat this cell does: - Creates a tiny conversation with system and user messages. - Calls the model llama3-70b-8192 for higher-quality outputs compared to 8B. - Prints the model‚Äôs reply.\nYou can modify the user content and re-run to see different responses.\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Be concise.\"},\n    {\"role\": \"user\", \"content\": \"Explain what a Large Language Model is in two sentences.\"}\n]\n\nresponse = client.chat.completions.create(\n    model=model,\n    messages=messages,\n    temperature=0 # lower temperature -&gt; more deterministic\n)\n\nprint(response.choices[0].message.content)\n\nA Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\n\n\n\nExamining the response object\n\nfor str in response:\n    print(str)\n\n('id', 'chatcmpl-60e9c394-acc3-4abb-b0e8-a0f03fdf247a')\n('choices', [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))])\n('created', 1761253879)\n('model', 'llama-3.3-70b-versatile')\n('object', 'chat.completion')\n('service_tier', 'on_demand')\n('system_fingerprint', 'fp_4cfc2deea6')\n('usage', CompletionUsage(completion_tokens=78, prompt_tokens=57, total_tokens=135, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.17950201, prompt_time=0.004199205, completion_time=0.156019343, total_time=0.160218548))\n('usage_breakdown', None)\n('x_groq', {'id': 'req_01k89ejtxpegtvrr9b9v8ep3s6'})\n\n\n\nresponse.choices[0]\n\nChoice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "01_introduction_llm.html#understanding-temperature",
    "href": "01_introduction_llm.html#understanding-temperature",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "4) Understanding temperature",
    "text": "4) Understanding temperature\nThe temperature parameter adjusts the randomness of token sampling. Intuitively, the model produces a probability distribution over possible next tokens from its logits \\(z\\). The temperature rescales those logits:\n\\[p_i = \\mathrm{softmax}\\!\\left(\\frac{z_i}{T}\\right) = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}.\\]\n\nLower \\(T\\) (e.g.¬†\\(T=0.2\\)): the distribution is sharper around high-probability tokens, yielding more stable outputs.\nHigher \\(T\\) (e.g.¬†\\(T=0.8\\)): the distribution is flatter, encouraging diversity and sometimes creativity.\n\nWhat this cell does: - Sends the same prompt twice, once with temperature=0.2 and once with temperature=0.8. - Prints both answers so you can compare tone and variability.\n\nprompt = \"Describe the role of LLMs in academic research in one sentence.\"\nfor temp in [0.2, 0.8]:\n    print(\"Temperature:\", temp)\n    for i in range(5):\n        response = client.chat.completions.create(\n            model=model,\n            messages=messages,\n            temperature=0 # lower temperature -&gt; more deterministic\n        )\n        print(response.choices[0].message.content)\n\nTemperature: 0.2\nA Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\nA Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\nA Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\nA Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating text based on the patterns and relationships it has learned from vast amounts of data. LLMs use complex algorithms and massive datasets to predict and create text, enabling applications such as language translation, text summarization, and conversational interfaces.\nA Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\nTemperature: 0.8\nA Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\nA Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\nA Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\nA Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\nA Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate human-like text, answer questions, and even engage in conversation, making them a powerful tool for various applications, including language translation, text summarization, and chatbots.",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "01_introduction_llm.html#continuous-conversation-keeping-history",
    "href": "01_introduction_llm.html#continuous-conversation-keeping-history",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "5) Continuous Conversation (Keeping History)",
    "text": "5) Continuous Conversation (Keeping History)\nLLM APIs do not keep state between calls. To build a conversation, you keep a list of messages and send the entire recent history each time. We‚Äôll implement a small helper that:\n\nAppends the user‚Äôs message to a global chat_history list.\nCalls the model with that history.\nAppends the assistant‚Äôs reply back into the history.\nReturns the latest reply for display.\n\nWe also keep the temperature low for focused answers. For longer chats, you can cap history to the last k turns to control token usage.\n\nchat_history = []\n\ndef chat(user_input, temperature=0.2, max_turns=8):\n    \"\"\"Send one user turn and get a reply, preserving context.\n    - Keeps system prompt + last `max_turns` user/assistant messages.\n    \"\"\"\n    chat_history.append({\"role\": \"user\", \"content\": user_input})\n\n    # Keep only the most recent `max_turns` pairs to control context size\n    system = chat_history[:1]\n    recent = chat_history[-(max_turns*2):] if len(chat_history) &gt; 1 else []\n    window = system + recent\n\n    resp = client.chat.completions.create(\n        model=model,\n        messages=window,\n        temperature=temperature,\n    )\n    reply = resp.choices[0].message.content\n    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n    return reply\n\n\nchat_history = [\n    {\"role\": \"system\", \"content\": \"Tailor your answers for a bioinformatician.\"}\n]\n\nchat(\"What is logistic regression?\")\nchat(\"How does it differ from linear regression?\")\n\nfor ch in chat_history:\n    print(ch)\n\n{'role': 'system', 'content': 'Tailor your answers for a bioinformatician.'}\n{'role': 'user', 'content': 'What is logistic regression?'}\n{'role': 'assistant', 'content': '**Logistic Regression**\\n=======================\\n\\nLogistic regression is a statistical method used for binary classification problems, where the goal is to predict a binary outcome (0/1, yes/no, etc.) based on one or more predictor variables. It is a widely used technique in bioinformatics, particularly in the analysis of high-throughput data, such as gene expression or genomic variation.\\n\\n**Mathematical Formulation**\\n---------------------------\\n\\nLogistic regression models the probability of a positive outcome (e.g., disease presence) using a logistic function, also known as a sigmoid function. The logistic function maps any real-valued number to a value between 0 and 1, which represents the probability of the positive outcome.\\n\\nThe logistic regression model can be formulated as:\\n\\np = 1 / (1 + e^(-z))\\n\\nwhere:\\n\\n* p is the probability of the positive outcome\\n* e is the base of the natural logarithm\\n* z is a linear combination of the predictor variables, weighted by coefficients (Œ≤)\\n\\nz = Œ≤0 + Œ≤1 \\\\* x1 + Œ≤2 \\\\* x2 + ‚Ä¶ + Œ≤n \\\\* xn\\n\\nwhere:\\n\\n* Œ≤0 is the intercept or bias term\\n* Œ≤1, Œ≤2, ‚Ä¶, Œ≤n are the coefficients for each predictor variable\\n* x1, x2, ‚Ä¶, xn are the predictor variables\\n\\n**Interpretation of Coefficients**\\n-------------------------------\\n\\nThe coefficients (Œ≤) in logistic regression represent the change in the log-odds of the positive outcome for a one-unit change in the predictor variable, while holding all other variables constant. The odds ratio (OR) can be calculated as e^Œ≤, which represents the multiplicative change in the odds of the positive outcome for a one-unit change in the predictor variable.\\n\\n**Common Applications in Bioinformatics**\\n-----------------------------------------\\n\\n1. **Gene expression analysis**: Logistic regression can be used to identify genes associated with a specific disease or phenotype.\\n2. **Genomic variation analysis**: Logistic regression can be used to identify genetic variants associated with a specific disease or trait.\\n3. **Protein function prediction**: Logistic regression can be used to predict the function of a protein based on its sequence or structural features.\\n4. **Classification of biological samples**: Logistic regression can be used to classify biological samples into different categories (e.g., cancer vs. normal tissue).\\n\\n**Example Code in Python**\\n---------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create logistic regression model\\nmodel = LogisticRegression()\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\nThis code snippet demonstrates how to use logistic regression to classify biological samples using the scikit-learn library in Python.'}\n{'role': 'user', 'content': 'How does it differ from linear regression?'}\n{'role': 'assistant', 'content': '**Differences between Logistic Regression and Linear Regression**\\n===========================================================\\n\\nLogistic regression and linear regression are both supervised learning algorithms used for regression tasks. However, they differ in their approach, application, and interpretation.\\n\\n**1. Outcome Variable**\\n----------------------\\n\\n* **Linear Regression**: The outcome variable is continuous, such as gene expression levels or protein concentrations.\\n* **Logistic Regression**: The outcome variable is binary (0/1, yes/no, etc.), such as disease presence or absence.\\n\\n**2. Model Formulation**\\n----------------------\\n\\n* **Linear Regression**: The model is formulated as a linear equation, where the outcome variable is a linear combination of the predictor variables.\\n\\t+ y = Œ≤0 + Œ≤1 \\\\* x1 + Œ≤2 \\\\* x2 + ‚Ä¶ + Œ≤n \\\\* xn\\n* **Logistic Regression**: The model is formulated as a logistic function, where the probability of the positive outcome is a non-linear function of the predictor variables.\\n\\t+ p = 1 / (1 + e^(-z))\\n\\t+ z = Œ≤0 + Œ≤1 \\\\* x1 + Œ≤2 \\\\* x2 + ‚Ä¶ + Œ≤n \\\\* xn\\n\\n**3. Cost Function**\\n-------------------\\n\\n* **Linear Regression**: The cost function is typically mean squared error (MSE) or mean absolute error (MAE).\\n* **Logistic Regression**: The cost function is typically cross-entropy loss or log loss.\\n\\n**4. Interpretation of Coefficients**\\n-----------------------------------\\n\\n* **Linear Regression**: The coefficients represent the change in the outcome variable for a one-unit change in the predictor variable.\\n* **Logistic Regression**: The coefficients represent the change in the log-odds of the positive outcome for a one-unit change in the predictor variable.\\n\\n**5. Assumptions**\\n-----------------\\n\\n* **Linear Regression**: Assumes linearity, independence, homoscedasticity, normality, and no multicollinearity.\\n* **Logistic Regression**: Assumes independence, no multicollinearity, and a binary outcome variable.\\n\\n**Example Code in Python**\\n---------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create linear regression model\\nlinear_model = LinearRegression()\\n\\n# Train linear model\\nlinear_model.fit(X_train, y_train)\\n\\n# Create logistic regression model\\nlogistic_model = LogisticRegression()\\n\\n# Train logistic model\\nlogistic_model.fit(X_train, (y_train &gt; 0).astype(int))\\n\\n# Evaluate models\\nlinear_accuracy = linear_model.score(X_test, y_test)\\nlogistic_accuracy = logistic_model.score(X_test, (y_test &gt; 0).astype(int))\\nprint(\"Linear Regression Accuracy:\", linear_accuracy)\\nprint(\"Logistic Regression Accuracy:\", logistic_accuracy)\\n```\\n\\nThis code snippet demonstrates how to use both linear regression and logistic regression to model continuous and binary outcome variables, respectively, using the scikit-learn library in Python.\\n\\n**Choosing between Linear Regression and Logistic Regression**\\n---------------------------------------------------------\\n\\n* Use linear regression when the outcome variable is continuous and the relationship between the predictor variables and the outcome variable is linear.\\n* Use logistic regression when the outcome variable is binary and the relationship between the predictor variables and the outcome variable is non-linear.'}\n\n\n\nchat(\"what are some other classification methods?\")\n\nfor ch in chat_history:\n    print(ch)\n\n{'role': 'system', 'content': 'Tailor your answers for a bioinformatician.'}\n{'role': 'user', 'content': 'What is logistic regression?'}\n{'role': 'assistant', 'content': '**Logistic Regression**\\n=======================\\n\\nLogistic regression is a statistical method used for binary classification problems, where the goal is to predict a binary outcome (0/1, yes/no, etc.) based on one or more predictor variables. It is a widely used technique in bioinformatics, particularly in the analysis of high-throughput data, such as gene expression or genomic variation.\\n\\n**Mathematical Formulation**\\n---------------------------\\n\\nLogistic regression models the probability of a positive outcome (e.g., disease presence) using a logistic function, also known as a sigmoid function. The logistic function maps any real-valued number to a value between 0 and 1, which represents the probability of the positive outcome.\\n\\nThe logistic regression model can be formulated as:\\n\\np = 1 / (1 + e^(-z))\\n\\nwhere:\\n\\n* p is the probability of the positive outcome\\n* e is the base of the natural logarithm\\n* z is a linear combination of the predictor variables, weighted by coefficients (Œ≤)\\n\\nz = Œ≤0 + Œ≤1 \\\\* x1 + Œ≤2 \\\\* x2 + ‚Ä¶ + Œ≤n \\\\* xn\\n\\nwhere:\\n\\n* Œ≤0 is the intercept or bias term\\n* Œ≤1, Œ≤2, ‚Ä¶, Œ≤n are the coefficients for each predictor variable\\n* x1, x2, ‚Ä¶, xn are the predictor variables\\n\\n**Interpretation of Coefficients**\\n-------------------------------\\n\\nThe coefficients (Œ≤) in logistic regression represent the change in the log-odds of the positive outcome for a one-unit change in the predictor variable, while holding all other variables constant. The odds ratio (OR) can be calculated as e^Œ≤, which represents the multiplicative change in the odds of the positive outcome for a one-unit change in the predictor variable.\\n\\n**Common Applications in Bioinformatics**\\n-----------------------------------------\\n\\n1. **Gene expression analysis**: Logistic regression can be used to identify genes associated with a specific disease or phenotype.\\n2. **Genomic variation analysis**: Logistic regression can be used to identify genetic variants associated with a specific disease or trait.\\n3. **Protein function prediction**: Logistic regression can be used to predict the function of a protein based on its sequence or structural features.\\n4. **Classification of biological samples**: Logistic regression can be used to classify biological samples into different categories (e.g., cancer vs. normal tissue).\\n\\n**Example Code in Python**\\n---------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create logistic regression model\\nmodel = LogisticRegression()\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\nThis code snippet demonstrates how to use logistic regression to classify biological samples using the scikit-learn library in Python.'}\n{'role': 'user', 'content': 'How does it differ from linear regression?'}\n{'role': 'assistant', 'content': '**Differences between Logistic Regression and Linear Regression**\\n===========================================================\\n\\nLogistic regression and linear regression are both supervised learning algorithms used for regression tasks. However, they differ in their approach, application, and interpretation.\\n\\n**1. Outcome Variable**\\n----------------------\\n\\n* **Linear Regression**: The outcome variable is continuous, such as gene expression levels or protein concentrations.\\n* **Logistic Regression**: The outcome variable is binary (0/1, yes/no, etc.), such as disease presence or absence.\\n\\n**2. Model Formulation**\\n----------------------\\n\\n* **Linear Regression**: The model is formulated as a linear equation, where the outcome variable is a linear combination of the predictor variables.\\n\\t+ y = Œ≤0 + Œ≤1 \\\\* x1 + Œ≤2 \\\\* x2 + ‚Ä¶ + Œ≤n \\\\* xn\\n* **Logistic Regression**: The model is formulated as a logistic function, where the probability of the positive outcome is a non-linear function of the predictor variables.\\n\\t+ p = 1 / (1 + e^(-z))\\n\\t+ z = Œ≤0 + Œ≤1 \\\\* x1 + Œ≤2 \\\\* x2 + ‚Ä¶ + Œ≤n \\\\* xn\\n\\n**3. Cost Function**\\n-------------------\\n\\n* **Linear Regression**: The cost function is typically mean squared error (MSE) or mean absolute error (MAE).\\n* **Logistic Regression**: The cost function is typically cross-entropy loss or log loss.\\n\\n**4. Interpretation of Coefficients**\\n-----------------------------------\\n\\n* **Linear Regression**: The coefficients represent the change in the outcome variable for a one-unit change in the predictor variable.\\n* **Logistic Regression**: The coefficients represent the change in the log-odds of the positive outcome for a one-unit change in the predictor variable.\\n\\n**5. Assumptions**\\n-----------------\\n\\n* **Linear Regression**: Assumes linearity, independence, homoscedasticity, normality, and no multicollinearity.\\n* **Logistic Regression**: Assumes independence, no multicollinearity, and a binary outcome variable.\\n\\n**Example Code in Python**\\n---------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create linear regression model\\nlinear_model = LinearRegression()\\n\\n# Train linear model\\nlinear_model.fit(X_train, y_train)\\n\\n# Create logistic regression model\\nlogistic_model = LogisticRegression()\\n\\n# Train logistic model\\nlogistic_model.fit(X_train, (y_train &gt; 0).astype(int))\\n\\n# Evaluate models\\nlinear_accuracy = linear_model.score(X_test, y_test)\\nlogistic_accuracy = logistic_model.score(X_test, (y_test &gt; 0).astype(int))\\nprint(\"Linear Regression Accuracy:\", linear_accuracy)\\nprint(\"Logistic Regression Accuracy:\", logistic_accuracy)\\n```\\n\\nThis code snippet demonstrates how to use both linear regression and logistic regression to model continuous and binary outcome variables, respectively, using the scikit-learn library in Python.\\n\\n**Choosing between Linear Regression and Logistic Regression**\\n---------------------------------------------------------\\n\\n* Use linear regression when the outcome variable is continuous and the relationship between the predictor variables and the outcome variable is linear.\\n* Use logistic regression when the outcome variable is binary and the relationship between the predictor variables and the outcome variable is non-linear.'}\n{'role': 'user', 'content': 'what are some other classification methods?'}\n{'role': 'assistant', 'content': '**Other Classification Methods**\\n=============================\\n\\nBesides logistic regression, there are several other classification methods used in bioinformatics and machine learning. Here are some of the most common ones:\\n\\n### 1. **Decision Trees**\\n\\n* **Description**: Decision trees are a type of supervised learning algorithm that uses a tree-like model to classify data.\\n* **Application**: Decision trees are useful for handling categorical data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create decision tree model\\nmodel = DecisionTreeClassifier()\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 2. **Random Forests**\\n\\n* **Description**: Random forests are an ensemble learning method that combines multiple decision trees to improve the accuracy and robustness of the model.\\n* **Application**: Random forests are useful for handling high-dimensional data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create random forest model\\nmodel = RandomForestClassifier(n_estimators=100)\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 3. **Support Vector Machines (SVMs)**\\n\\n* **Description**: SVMs are a type of supervised learning algorithm that uses a hyperplane to separate the data into different classes.\\n* **Application**: SVMs are useful for handling high-dimensional data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create SVM model\\nmodel = SVC(kernel=\"linear\")\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 4. **K-Nearest Neighbors (KNN)**\\n\\n* **Description**: KNN is a type of supervised learning algorithm that uses the k-nearest neighbors to classify new data points.\\n* **Application**: KNN is useful for handling small datasets and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create KNN model\\nmodel = KNeighborsClassifier(n_neighbors=5)\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 5. **Neural Networks**\\n\\n* **Description**: Neural networks are a type of supervised learning algorithm that uses a network of interconnected nodes (neurons) to classify data.\\n* **Application**: Neural networks are useful for handling complex, high-dimensional data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create neural network model\\nmodel = MLPClassifier(hidden_layer_sizes=(10, 10))\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 6. **Gradient Boosting**\\n\\n* **Description**: Gradient boosting is an ensemble learning method that combines multiple weak models to create a strong predictive model.\\n* **Application**: Gradient boosting is useful for handling high-dimensional data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create gradient boosting model\\nmodel = GradientBoostingClassifier(n_estimators=100)\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\nThese are just a few examples of the many classification methods available in bioinformatics and machine learning. The choice of method depends on the specific problem, dataset, and performance metrics.'}",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "01_introduction_llm.html#exercise-your-first-prompt",
    "href": "01_introduction_llm.html#exercise-your-first-prompt",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "8) Exercise ‚Äî Your First Prompt",
    "text": "8) Exercise ‚Äî Your First Prompt\nTry your own research-related prompts. A few ideas:\n\nSummarise your current project in one paragraph.\nAsk for three open research questions in your field.\nRequest a draft methods paragraph describing your dataset and analysis steps.\n\nRemember you can tweak temperature to trade off consistency vs creativity.\n\nchat_history = [\n    {\"role\": \"system\", \"content\": \"Tailor your answers for a bioinformatician.\"}\n]\n\n\n# Example: replace with your own question(s)\nprint(chat(\"Summarise the challenges in renewable energy policy research.\"))\n\nAs a bioinformatician, you're likely familiar with complex systems and data-driven approaches. Renewable energy policy research presents several challenges that can be broken down into the following categories:\n\n1. **Integration and Interoperability**: Renewable energy sources, such as solar and wind power, have variable output, making it challenging to integrate them into existing energy grids. This requires advanced forecasting, grid management, and energy storage systems.\n2. **Data Quality and Availability**: High-quality, granular data on energy production, consumption, and grid operations is essential for informed policy decisions. However, data gaps, inconsistencies, and lack of standardization hinder research and policy development.\n3. **Complexity and Uncertainty**: Renewable energy systems involve complex interactions between technological, economic, social, and environmental factors. Uncertainties, such as climate change and policy fluctuations, make it difficult to predict outcomes and develop effective policies.\n4. **Scalability and Spatial Analysis**: Renewable energy deployment requires consideration of spatial factors, such as land use, resource availability, and infrastructure. Scalability issues arise when trying to balance local, regional, and global energy demands with available resources.\n5. **Stakeholder Engagement and Social Acceptance**: Effective policy development requires engagement with diverse stakeholders, including communities, industries, and governments. Social acceptance of renewable energy technologies and infrastructure can be a significant challenge.\n6. **Economic and Financial Analysis**: Renewable energy policies often involve economic incentives, subsidies, and investments. Accurate economic and financial analysis is necessary to evaluate policy effectiveness, but this can be complicated by factors like technology costs, market volatility, and externalities.\n7. **Policy Frameworks and Governance**: Renewable energy policies must navigate existing regulatory frameworks, which can be inadequate or inconsistent. Effective governance structures, including international cooperation and national policies, are essential for supporting the transition to renewable energy.\n8. **Technological Innovation and Deployment**: The rapid evolution of renewable energy technologies creates challenges for policy development, as new technologies and innovations can disrupt existing markets and infrastructure.\n9. **Energy Justice and Equity**: Renewable energy policies must address issues of energy access, affordability, and equity, particularly for marginalized communities. This requires careful consideration of social and environmental impacts.\n10. **Long-term Planning and Scenario Development**: Renewable energy policy research requires long-term planning and scenario development to anticipate future energy demands, technology advancements, and potential risks.\n\nTo address these challenges, researchers can employ a range of bioinformatics-inspired approaches, such as:\n\n* Data integration and analytics\n* Machine learning and predictive modeling\n* Network analysis and simulation\n* Spatial analysis and geospatial modeling\n* Stakeholder engagement and participatory modeling\n* Scenario planning and uncertainty analysis\n\nBy leveraging these approaches, researchers can develop more effective renewable energy policies that balance technological, economic, social, and environmental considerations.",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "01_introduction_llm.html#wrap-up-next-steps",
    "href": "01_introduction_llm.html#wrap-up-next-steps",
    "title": "Introduction to Large Language Models (LLMs) for Research",
    "section": "9) Wrap-Up & Next Steps",
    "text": "9) Wrap-Up & Next Steps\n\nYou configured an OpenAI-compatible client to talk to Groq.\nYou sent your first prompts using Llama-3 70B and explored the impact of temperature.\nYou kept conversation state locally in a Python list and learned how to save it.\n\nIn the next notebook, we‚Äôll connect to a scholarly API to fetch abstracts and practice literature summarisation and structured extraction.\nKey terms: tokens, temperature, logits, softmax, stateless API, chat history.",
    "crumbs": [
      "01_introduction_llm"
    ]
  },
  {
    "objectID": "03_literature_review.html",
    "href": "03_literature_review.html",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "This notebook demonstrates how to automate parts of a literature review using:\n\nArXiv API to fetch paper metadata and abstracts\nGroq (Llama-3 70B) to summarise and extract structured information\nPandas / Matplotlib to aggregate and visualise results\n\nclear markdown explanations and thorough code comments are included before every step.\n\n\n\nUse public APIs (arXiv or other databases) to fetch paper metadata.\nUse Llama-3 70B to summarise abstracts.\nExtract structured metadata: study type, method, findings.\nCompare and synthesise multiple papers.\n\nWorkflow: 1. Fetch results by keyword (e.g., quantum batteries) into a DataFrame. 2. Summarise single abstract with chat(). 3. Batch summarise and extract structured fields (method, sample/setting, main finding). 4. (Optional) Download PDFs for top N and extract crude text. 5. Save a CSV for use in the RAG notebook.\n\nüîç Introduction: why automate literature review?\nResearchers face several bottlenecks during literature review: - Volume: thousands of papers, preprints, and conference proceedings. - Summarisation: abstracts and conclusions need to be condensed to core ideas. - Synthesis: comparing findings and methods across studies is time-consuming.\nAn LLM can help by generating concise summaries and extracting structured fields (e.g., study type, sample size), enabling quick aggregation and visualisation. However, human validation is essential ‚Äî the model can hallucinate details or misinterpret ambiguous text.\n\n\n\nYou need to paste your Groq SPI key here!\n\n# --- Groq API Settings ---\n# Paste your Groq API key below (between quotes).\n# Note: This is NOT a secure way to store secrets if you share the notebook.\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = \"\"  # &lt;-- replace with your key (e.g., \"gsk_...\")\nmodel = \"llama-3.3-70b-versatile\"  # Select your model https://console.groq.com/docs/models\nos.environ[\"BASE_URL\"] = \"https://api.groq.com/openai/v1\"  # Groq uses an OpenAI-compatible API surface\nprint(\"Groq settings configured. (Remember to paste your API key!)\")\n\nGroq settings configured. (Remember to paste your API key!)\n\n\n\n\n\n\n# --- Create the OpenAI-compatible client + chat() helper ---\nfrom openai import OpenAI\n\nchat_history = []  # running memory\n\n# Create the client\nclient = OpenAI(\n    api_key=os.environ[\"GROQ_API_KEY\"],\n    base_url=os.environ[\"BASE_URL\"],\n)\n\ndef set_system(prompt: str):\n    \"\"\"Reset chat history to a single system message.\"\"\"\n    global chat_history\n    chat_history = [{\"role\": \"system\", \"content\": prompt}]\n    return chat_history\n\ndef clear_chat():\n    \"\"\"Clear all chat history.\"\"\"\n    global chat_history\n    chat_history = []\n    return chat_history\n\ndef chat(user_input, temperature=0.2, max_turns=8):\n    \"\"\"Send one user turn and get a reply, preserving context.\n    - Keeps system prompt + last `max_turns` user/assistant messages.\n    \"\"\"\n    chat_history.append({\"role\": \"user\", \"content\": user_input})\n\n    # Keep only the most recent `max_turns` pairs to control context size\n    system = chat_history[:1]\n    recent = chat_history[-(max_turns*2):] if len(chat_history) &gt; 1 else []\n    window = system + recent\n\n    resp = client.chat.completions.create(\n        model=model,\n        messages=window,\n        temperature=temperature,\n    )\n    reply = resp.choices[0].message.content\n    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n    return reply\n\nprint(\"Testing API ...\")\nprint()\nprint(\"User:\")\nprint(\"Hello LLM!\")\nprint(\"LLM:\")\nprint(chat(\"Hello LLM!\"))\nprint()\nprint(\"Client ready. Use chat('...'), set_system('...'), clear_chat().\")\n\nTesting API ...\n\nUser:\nHello LLM!\nLLM:\nHello! It's nice to meet you. Is there something I can help you with or would you like to chat?\n\nClient ready. Use chat('...'), set_system('...'), clear_chat().\n\n\n\n# (Optional) One-time installs (run locally if needed)\n# %pip install arxiv pandas matplotlib pypdf requests\nimport pandas as pd\nimport time\nimport pathlib, json\nfrom typing import List, Dict, Any\n\n# Matplotlib for simple charts\nimport matplotlib.pyplot as plt\nplt.rcParams.update({\"figure.figsize\": (6,4)})\n\nDATA_DIR = pathlib.Path(\"literature_data\")\nDATA_DIR.mkdir(exist_ok=True)\n\n\n\n\n\n\nimport re\nimport requests\nimport pandas as pd\n\ndef search_arxiv(query: str, max_results: int = 20) -&gt; pd.DataFrame:\n    \"\"\"Basic arXiv search via their Atom feed.\n    Note: For production, consider using the `arxiv` Python package.\n    \"\"\"\n    base = \"http://export.arxiv.org/api/query\"\n    params = {\n        \"search_query\": query,\n        \"start\": 0,\n        \"max_results\": max_results,\n        \"sortBy\": \"relevance\",\n        \"sortOrder\": \"descending\",\n    }\n    r = requests.get(base, params=params, timeout=30)\n    r.raise_for_status()\n    text = r.text\n\n    # Crude parsing (avoid external deps). For robust parsing use feedparser.\n    entries = text.split(\"&lt;entry&gt;\")[1:]\n    rows = []\n    for raw in entries:\n        def _extract(tag):\n            m = re.search(fr\"&lt;{tag}&gt;(.*?)&lt;/{tag}&gt;\", raw, flags=re.S)\n            return (m.group(1).strip() if m else \"\")\n        title = re.sub(r\"\\s+\", \" \", _extract(\"title\"))\n        summary = re.sub(r\"\\s+\", \" \", _extract(\"summary\"))\n        published = _extract(\"published\").split(\"T\")[0]\n        link_m = re.search(r'&lt;link rel=\"alternate\" type=\"text/html\" href=\"(.*?)\"', raw)\n        link = link_m.group(1) if link_m else \"\"\n        pdf_m = re.search(r'&lt;link title=\"pdf\" href=\"(.*?)\"', raw)\n        pdf = pdf_m.group(1) if pdf_m else \"\"\n        authors = re.findall(r\"&lt;name&gt;(.*?)&lt;/name&gt;\", raw)\n        rows.append({\n            \"title\": title,\n            \"summary\": summary,\n            \"published\": published,\n            \"link\": link,\n            \"pdf\": pdf,\n            \"authors\": \", \".join(authors),\n        })\n    return pd.DataFrame(rows)\n\n\ndef summarise_abstract(abstract: str, topic: str = \"general\") -&gt; str:\n    \"\"\"Use the global chat() to generate a concise summary of an abstract.\"\"\"\n    set_system(\"You are a helpful research assistant. Summarise abstracts concisely and faithfully.\")\n    prompt = f\"\"\"Summarise the following scientific abstract in 3-4 sentences.\n    Focus on goals, methods, and key findings. Topic: {topic}.\n\n    Abstract:\n    {abstract}\n    \"\"\"\n    return chat(prompt, temperature=0.1)\n\n\ndef extract_structured_info(abstract: str) -&gt; Dict[str, Any]:\n    \"\"\"Extract {methodology, data/context, finding, limitations} ‚Äî simple, forgiving version.\"\"\"\n    set_system(\"You convert abstracts into structured JSON with fields: methodology, data, finding, limitations.\")\n    prompt = f\"\"\"Read the abstract below and return a JSON object with keys:\n    methodology, data, finding, limitations. Keep values short and faithful to the text.\n\n    Abstract:\n    {abstract}\n    \"\"\"\n    raw = chat(prompt, temperature=0.0)\n\n    # Remove Markdown fences if present\n    cleaned = raw.strip().removeprefix(\"```json\").removeprefix(\"```\").removesuffix(\"```\").strip()\n\n    try:\n        obj = json.loads(cleaned)\n        if isinstance(obj, dict):\n            # Fill missing keys so nothing stays empty\n            for k in [\"methodology\", \"data\", \"finding\", \"limitations\"]:\n                obj[k] = obj.get(k, \"\").strip() or \"Not clearly specified\"\n            return obj\n    except Exception:\n        pass\n\n    # Fallback if parsing still fails\n    return {\n        \"methodology\": raw,\n        \"data\": \"Not clearly specified\",\n        \"finding\": \"Not clearly specified\",\n        \"limitations\": \"Not clearly specified\",\n    }\n\n\ndef download_pdf(url: str, dest_dir: pathlib.Path) -&gt; pathlib.Path:\n    \"\"\"Download a PDF to dest_dir, return path. Simple and naive.\"\"\"\n    fn = dest_dir / (url.rstrip(\"/\").split(\"/\")[-1] + \".pdf\" if not url.endswith(\".pdf\") else url.split(\"/\")[-1])\n    with requests.get(url, stream=True, timeout=60) as r:\n        r.raise_for_status()\n        with open(fn, \"wb\") as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n    return fn\n\n\nfrom pypdf import PdfReader\n\ndef extract_pdf_text(pdf_path: pathlib.Path, max_pages: int = 10) -&gt; str:\n    \"\"\"Crude text extraction using pypdf (first max_pages).\"\"\"\n    text = []\n    reader = PdfReader(str(pdf_path))\n    for i, page in enumerate(reader.pages):\n        if i &gt;= max_pages:\n            break\n        try:\n            text.append(page.extract_text() or \"\")\n        except Exception:\n            pass\n    return \"\\n\".join(text)\n\n\n\n\n\n\n\nWe will query the ArXiv API for works matching a keyword (e.g., ‚Äúquantum batteries‚Äù). ArXiv provides abstracts and metadata like publication year.\n‚ö†Ô∏è Network note: This requires internet access. If running on an offline HPC, pre-fetch and cache JSON responses.\n\nquery = \"quantum batteries\"  # change freely\ndf = search_arxiv(query, max_results=10)\nprint(f\"Fetched {len(df)} results for query: {query!r}\")\ndf.head(5)\n\nFetched 10 results for query: 'quantum batteries'\n\n\n\n\n\n\n\n\n\ntitle\nsummary\npublished\nlink\npdf\nauthors\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\n2024-05-06\n\nhttp://arxiv.org/pdf/2405.03093v1\nTinggui Zhang, Hong Yang, Shao-Ming Fei\n\n\n1\nEntanglement and energy transportation in the ...\nQuantum battery exploits the principle of quan...\n2025-02-11\n\nhttp://arxiv.org/pdf/2502.07513v1\nFan Liu, Hui-Yu Yang, Shuai-Li Wang, Jun-Zhong...\n\n\n2\nHigh-performance Kerr quantum battery\nWe propose and investigate the performance of ...\n2023-05-04\n\nhttp://arxiv.org/pdf/2305.03202v2\nMuhammad Shoufie Ukhtary, Ahmad R. T. Nugraha,...\n\n\n3\nDual-cavity controllable quantum battery\nWith the rapid development of quantum science ...\n2024-06-10\n\nhttp://arxiv.org/pdf/2406.06383v2\nDayang Zhang, Shuangquan Ma, Yunxiu Jiang, You...\n\n\n4\nOptimizing quantum battery performance by redu...\nQuantum batteries have emerged as promising de...\n2025-05-12\n\nhttp://arxiv.org/pdf/2505.08029v1\nRohit Kumar Shukla, Rajiv Kumar, Ujjwal Sen, S...\n\n\n\n\n\n\n\n\n\n\nüß© Summarise a single abstract with Llama-3 70B\nNow we connect to the Groq API (OpenAI-compatible) and ask Llama-3 70B to produce a concise summary of one abstract.\n‚ö†Ô∏è Remember, if you restart the kernel, you must re-set your API key.\n\n\nabstract = df.loc[0, \"summary\"]\nclear_chat()  # start fresh\nshort_sum = summarise_abstract(abstract, topic=query)\nstructs = extract_structured_info(abstract)\nprint(short_sum)\nprint(structs)\n\nResearchers investigated methods to enhance the capacity of quantum batteries, a crucial aspect for their potential applications. They focused on bipartite quantum systems and explored the effect of local projective measurements on a subsystem of the quantum state. Using two-qubit Bell-diagonal states and X-type states as examples, the study found that local projective measurements can improve the quantum battery capacity for both the whole system and a subsystem. The theoretical findings aim to provide guidance for the experimental development of quantum batteries with improved capacity.\n{'methodology': 'Local projective measurements on bipartite quantum systems', 'data': 'Two-qubit Bell-diagonal and X-type states', 'finding': 'Local measurements can improve quantum battery capacity', 'limitations': 'Theoretical analysis, experimental development needed'}\n\n\n\n\n\nLoop over all abstracts to create a summary_llm and structured columns.\nWhat this cell does: - Iterates over the rows. - Calls the LLM for a 3-4 sentence summary. - Stores the result in a new summary column. - creates a jason output that contains: ‚Äúmethodology‚Äù:, ‚Äúdata‚Äù, ‚Äúfinding‚Äù and ‚Äúlimitations‚Äù. - Stores the result in a new structured column.\n\nsummaries = []\nstructs = []\nfor i, row in df.iterrows():\n    clear_chat()\n    s = summarise_abstract(row[\"summary\"], topic=query)\n    summaries.append(s)\n\n    clear_chat()\n    st = extract_structured_info(row[\"summary\"])\n    structs.append(st)\n    time.sleep(0.2)  # be gentle\n\n    print(f\"Processed {i}/{len(df)}\")\n\n\ndf[\"summary_llm\"] = summaries\ndf[\"structured\"] = structs\n\n\n\nProcessed 0/10\nProcessed 1/10\nProcessed 2/10\nProcessed 3/10\nProcessed 4/10\nProcessed 5/10\nProcessed 6/10\nProcessed 7/10\nProcessed 8/10\nProcessed 9/10\n\n\n\ndf.head(3)\n\n\n\n\n\n\n\n\ntitle\nsummary\npublished\nlink\npdf\nauthors\nsummary_llm\nstructured\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\n2024-05-06\n\nhttp://arxiv.org/pdf/2405.03093v1\nTinggui Zhang, Hong Yang, Shao-Ming Fei\nThis study explores methods to enhance the cap...\n{'methodology': 'Local projective measurements...\n\n\n1\nEntanglement and energy transportation in the ...\nQuantum battery exploits the principle of quan...\n2025-02-11\n\nhttp://arxiv.org/pdf/2502.07513v1\nFan Liu, Hui-Yu Yang, Shuai-Li Wang, Jun-Zhong...\nResearchers studied the central-spin quantum b...\n{'methodology': 'Invariant subspace method', '...\n\n\n2\nHigh-performance Kerr quantum battery\nWe propose and investigate the performance of ...\n2023-05-04\n\nhttp://arxiv.org/pdf/2305.03202v2\nMuhammad Shoufie Ukhtary, Ahmad R. T. Nugraha,...\nResearchers propose a \"Kerr quantum battery\" c...\n{'methodology': 'Proposed and investigated a h...\n\n\n\n\n\n\n\n\n\n\n\n# Count by year (based on 'published' YYYY-MM-DD -&gt; YYYY)\nyears = df[\"published\"].str.slice(0,4)\ncounts = years.value_counts().sort_index()\ncounts.plot(kind=\"bar\")\nplt.title(\"Papers per Year (arXiv results)\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport json, time, textwrap\n\ndef select_and_fetch_pdfs(\n    df: pd.DataFrame,\n    question: str,\n    k: int = 3,\n    max_pages: int = 8,\n    sleep_s: float = 0.5,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Use the LLM to select the k most relevant entries in df for the research question,\n    download their PDFs, extract crude text, and return a df_top with added columns:\n      - pdf_file\n      - crude_text\n\n    Requires: chat(), set_system(), clear_chat(), download_pdf(), extract_pdf_text(),\n              DATA_DIR (Path) to exist.\n    \"\"\"\n    assert {\"title\", \"summary\", \"link\", \"pdf\"}.issubset(df.columns), \"df must have title, summary, link, pdf\"\n\n    # 1) Prepare a short list for the model (index, title, short summary)\n    items = []\n    for i, row in df.iterrows():\n        t = str(row[\"title\"]).strip()\n        s = str(row[\"summary\"]).strip().replace(\"\\n\", \" \")\n        s = (s[:300] + \"‚Ä¶\") if len(s) &gt; 300 else s  # keep prompt small\n        items.append({\"idx\": int(i), \"title\": t, \"summary\": s})\n\n    shortlist = json.dumps(items, ensure_ascii=False)\n\n    # 2) Ask the model to return ONLY JSON with a list of the best indices\n    clear_chat()\n    set_system(\"Return ONLY valid JSON. No extra text or code fences.\")\n    prompt = f\"\"\"\nYou are selecting the most relevant papers for a research question.\n\nQUESTION:\n{question}\n\nHere is a list of candidates (index, title, summary):\n{shortlist}\n\nReturn ONLY JSON with this exact shape:\n{{\"best\": [idx1, idx2, ...]}}\n\nRules:\n- Choose exactly {k} unique indices.\n- Prefer titles/summaries that directly address the question.\n- Do not add explanations or extra keys.\n\"\"\"\n    raw = chat(textwrap.dedent(prompt).strip(), temperature=0.0)\n\n    # 3) Parse indices; simple fence stripping just in case\n    cleaned = raw.strip().removeprefix(\"```json\").removeprefix(\"```\").removesuffix(\"```\").strip()\n    try:\n        obj = json.loads(cleaned)\n        idxs = list(dict.fromkeys([int(x) for x in obj.get(\"best\", [])]))[:k]  # unique, max k\n    except Exception:\n        idxs = list(df.index)[:k]  # fallback: take head(k)\n\n    if len(idxs) &lt; k:\n        # pad with head(k) if model returned fewer than k\n        head_idxs = [i for i in df.index[:k] if i not in idxs]\n        idxs = (idxs + head_idxs)[:k]\n\n    # 4) Download PDFs and extract text\n    pdf_dir = DATA_DIR / \"full_texts\"\n    pdf_dir.mkdir(parents=True, exist_ok=True)\n\n    rows = []\n    for i in idxs:\n        row = df.loc[i]\n        url = row[\"pdf\"] or row[\"link\"]\n        pdf_name, crude = \"\", \"\"\n        if url:\n            try:\n                path = download_pdf(url, pdf_dir)\n                pdf_name = path.name\n                crude = extract_pdf_text(path, max_pages=max_pages)\n            except Exception as e:\n                print(f\"Failed for idx {i}: {e}\")\n        rows.append({**row.to_dict(), \"pdf_file\": pdf_name, \"crude_text\": crude})\n        time.sleep(sleep_s)\n\n    df_top = pd.DataFrame(rows).reset_index(drop=True)\n    return df_top\n\n\nquestion = \"What experimental or theoretical methods advance quantum batteries most effectively?\"\ndf_top = select_and_fetch_pdfs(df, question, k=3, max_pages=8)\ndf_top.head(3)\n\n\n\n\n\n\n\n\ntitle\nsummary\npublished\nlink\npdf\nauthors\nsummary_llm\nstructured\npdf_file\ncrude_text\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\n2024-05-06\n\nhttp://arxiv.org/pdf/2405.03093v1\nTinggui Zhang, Hong Yang, Shao-Ming Fei\nThis study explores methods to enhance the cap...\n{'methodology': 'Local projective measurements...\n2405.03093v1.pdf\narXiv:2405.03093v1 [quant-ph] 6 May 2024\\nLo...\n\n\n1\nOptimizing quantum battery performance by redu...\nQuantum batteries have emerged as promising de...\n2025-05-12\n\nhttp://arxiv.org/pdf/2505.08029v1\nRohit Kumar Shukla, Rajiv Kumar, Ujjwal Sen, S...\nResearchers investigated the dynamics of quant...\n{'methodology': 'Investigating interplay betwe...\n2505.08029v1.pdf\narXiv:2505.08029v1 [quant-ph] 12 May 2025\\nO...\n\n\n2\nEfficient charging of multiple open quantum ba...\nWe explore a protocol that efficiently charges...\n2024-10-25\n\nhttp://arxiv.org/pdf/2410.19303v1\nJosephine Dias, Hui Wang, Kae Nemoto, Franco N...\nThis study aims to develop an efficient protoc...\n{'methodology': 'protocol using collective cou...\n2410.19303v1.pdf\nEfficient charging of multiple open quantum ba...\n\n\n\n\n\n\n\n\n\n\n\nInstead of asking the LLM directly, each abstract and the research question can be converted into vector embeddings using a sentence or document encoder (e.g., Sentence-Transformers, OpenAI text-embedding-3-small, or Groq‚Äôs embedding models*).\nRelevance is then computed via cosine similarity, and the top-K most similar abstracts are selected.\n\nPros: Fast, reproducible, and explainable.\n\nCons: Requires an embedding model.\n\nTypical use: The foundation of most RAG (Retrieval-Augmented Generation) systems.\n\n\n\n\n\nAnother approach is to define specific evaluation criteria and let the LLM (or a human reviewer) score each abstract numerically.\nFor example, score each paper from 1‚Äì5 on: - Method novelty\n- Data similarity to your question\n- Domain alignment\n- Practical applicability\nYou can then compute a weighted average or composite score to select the top-K.\nThis method is especially useful for research evaluation, grant triaging, or systematic reviews, where transparency and criteria consistency matter.\n\n\n\n\n\n\nout_csv = DATA_DIR / \"literature_corpus.csv\"\ndf.to_csv(out_csv, index=False)\nprint(\"Saved:\", out_csv.resolve())\n\nout_csv = DATA_DIR / \"literature_corpus_top.csv\"\ndf_top.to_csv(out_csv, index=False)\nprint(\"Saved:\", out_csv.resolve())\n\nSaved: C:\\code\\llm_tutorial\\literature_data\\literature_corpus.csv\nSaved: C:\\code\\llm_tutorial\\literature_data\\literature_corpus_top.csv\n\n\n\n\n\nYou fetched paper metadata into a DataFrame.\nYou used chat() with a resettable memory for summarisation and structured extraction.\nYou (optionally) downloaded PDFs and extracted crude text.\nYou saved literature_corpus.csv for the next RAG notebook.",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "03_literature_review.html#objectives",
    "href": "03_literature_review.html#objectives",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "Use public APIs (arXiv or other databases) to fetch paper metadata.\nUse Llama-3 70B to summarise abstracts.\nExtract structured metadata: study type, method, findings.\nCompare and synthesise multiple papers.\n\nWorkflow: 1. Fetch results by keyword (e.g., quantum batteries) into a DataFrame. 2. Summarise single abstract with chat(). 3. Batch summarise and extract structured fields (method, sample/setting, main finding). 4. (Optional) Download PDFs for top N and extract crude text. 5. Save a CSV for use in the RAG notebook.\n\nüîç Introduction: why automate literature review?\nResearchers face several bottlenecks during literature review: - Volume: thousands of papers, preprints, and conference proceedings. - Summarisation: abstracts and conclusions need to be condensed to core ideas. - Synthesis: comparing findings and methods across studies is time-consuming.\nAn LLM can help by generating concise summaries and extracting structured fields (e.g., study type, sample size), enabling quick aggregation and visualisation. However, human validation is essential ‚Äî the model can hallucinate details or misinterpret ambiguous text.\n\n\n\nYou need to paste your Groq SPI key here!\n\n# --- Groq API Settings ---\n# Paste your Groq API key below (between quotes).\n# Note: This is NOT a secure way to store secrets if you share the notebook.\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = \"\"  # &lt;-- replace with your key (e.g., \"gsk_...\")\nmodel = \"llama-3.3-70b-versatile\"  # Select your model https://console.groq.com/docs/models\nos.environ[\"BASE_URL\"] = \"https://api.groq.com/openai/v1\"  # Groq uses an OpenAI-compatible API surface\nprint(\"Groq settings configured. (Remember to paste your API key!)\")\n\nGroq settings configured. (Remember to paste your API key!)\n\n\n\n\n\n\n# --- Create the OpenAI-compatible client + chat() helper ---\nfrom openai import OpenAI\n\nchat_history = []  # running memory\n\n# Create the client\nclient = OpenAI(\n    api_key=os.environ[\"GROQ_API_KEY\"],\n    base_url=os.environ[\"BASE_URL\"],\n)\n\ndef set_system(prompt: str):\n    \"\"\"Reset chat history to a single system message.\"\"\"\n    global chat_history\n    chat_history = [{\"role\": \"system\", \"content\": prompt}]\n    return chat_history\n\ndef clear_chat():\n    \"\"\"Clear all chat history.\"\"\"\n    global chat_history\n    chat_history = []\n    return chat_history\n\ndef chat(user_input, temperature=0.2, max_turns=8):\n    \"\"\"Send one user turn and get a reply, preserving context.\n    - Keeps system prompt + last `max_turns` user/assistant messages.\n    \"\"\"\n    chat_history.append({\"role\": \"user\", \"content\": user_input})\n\n    # Keep only the most recent `max_turns` pairs to control context size\n    system = chat_history[:1]\n    recent = chat_history[-(max_turns*2):] if len(chat_history) &gt; 1 else []\n    window = system + recent\n\n    resp = client.chat.completions.create(\n        model=model,\n        messages=window,\n        temperature=temperature,\n    )\n    reply = resp.choices[0].message.content\n    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n    return reply\n\nprint(\"Testing API ...\")\nprint()\nprint(\"User:\")\nprint(\"Hello LLM!\")\nprint(\"LLM:\")\nprint(chat(\"Hello LLM!\"))\nprint()\nprint(\"Client ready. Use chat('...'), set_system('...'), clear_chat().\")\n\nTesting API ...\n\nUser:\nHello LLM!\nLLM:\nHello! It's nice to meet you. Is there something I can help you with or would you like to chat?\n\nClient ready. Use chat('...'), set_system('...'), clear_chat().\n\n\n\n# (Optional) One-time installs (run locally if needed)\n# %pip install arxiv pandas matplotlib pypdf requests\nimport pandas as pd\nimport time\nimport pathlib, json\nfrom typing import List, Dict, Any\n\n# Matplotlib for simple charts\nimport matplotlib.pyplot as plt\nplt.rcParams.update({\"figure.figsize\": (6,4)})\n\nDATA_DIR = pathlib.Path(\"literature_data\")\nDATA_DIR.mkdir(exist_ok=True)",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "03_literature_review.html#helper-functions",
    "href": "03_literature_review.html#helper-functions",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "import re\nimport requests\nimport pandas as pd\n\ndef search_arxiv(query: str, max_results: int = 20) -&gt; pd.DataFrame:\n    \"\"\"Basic arXiv search via their Atom feed.\n    Note: For production, consider using the `arxiv` Python package.\n    \"\"\"\n    base = \"http://export.arxiv.org/api/query\"\n    params = {\n        \"search_query\": query,\n        \"start\": 0,\n        \"max_results\": max_results,\n        \"sortBy\": \"relevance\",\n        \"sortOrder\": \"descending\",\n    }\n    r = requests.get(base, params=params, timeout=30)\n    r.raise_for_status()\n    text = r.text\n\n    # Crude parsing (avoid external deps). For robust parsing use feedparser.\n    entries = text.split(\"&lt;entry&gt;\")[1:]\n    rows = []\n    for raw in entries:\n        def _extract(tag):\n            m = re.search(fr\"&lt;{tag}&gt;(.*?)&lt;/{tag}&gt;\", raw, flags=re.S)\n            return (m.group(1).strip() if m else \"\")\n        title = re.sub(r\"\\s+\", \" \", _extract(\"title\"))\n        summary = re.sub(r\"\\s+\", \" \", _extract(\"summary\"))\n        published = _extract(\"published\").split(\"T\")[0]\n        link_m = re.search(r'&lt;link rel=\"alternate\" type=\"text/html\" href=\"(.*?)\"', raw)\n        link = link_m.group(1) if link_m else \"\"\n        pdf_m = re.search(r'&lt;link title=\"pdf\" href=\"(.*?)\"', raw)\n        pdf = pdf_m.group(1) if pdf_m else \"\"\n        authors = re.findall(r\"&lt;name&gt;(.*?)&lt;/name&gt;\", raw)\n        rows.append({\n            \"title\": title,\n            \"summary\": summary,\n            \"published\": published,\n            \"link\": link,\n            \"pdf\": pdf,\n            \"authors\": \", \".join(authors),\n        })\n    return pd.DataFrame(rows)\n\n\ndef summarise_abstract(abstract: str, topic: str = \"general\") -&gt; str:\n    \"\"\"Use the global chat() to generate a concise summary of an abstract.\"\"\"\n    set_system(\"You are a helpful research assistant. Summarise abstracts concisely and faithfully.\")\n    prompt = f\"\"\"Summarise the following scientific abstract in 3-4 sentences.\n    Focus on goals, methods, and key findings. Topic: {topic}.\n\n    Abstract:\n    {abstract}\n    \"\"\"\n    return chat(prompt, temperature=0.1)\n\n\ndef extract_structured_info(abstract: str) -&gt; Dict[str, Any]:\n    \"\"\"Extract {methodology, data/context, finding, limitations} ‚Äî simple, forgiving version.\"\"\"\n    set_system(\"You convert abstracts into structured JSON with fields: methodology, data, finding, limitations.\")\n    prompt = f\"\"\"Read the abstract below and return a JSON object with keys:\n    methodology, data, finding, limitations. Keep values short and faithful to the text.\n\n    Abstract:\n    {abstract}\n    \"\"\"\n    raw = chat(prompt, temperature=0.0)\n\n    # Remove Markdown fences if present\n    cleaned = raw.strip().removeprefix(\"```json\").removeprefix(\"```\").removesuffix(\"```\").strip()\n\n    try:\n        obj = json.loads(cleaned)\n        if isinstance(obj, dict):\n            # Fill missing keys so nothing stays empty\n            for k in [\"methodology\", \"data\", \"finding\", \"limitations\"]:\n                obj[k] = obj.get(k, \"\").strip() or \"Not clearly specified\"\n            return obj\n    except Exception:\n        pass\n\n    # Fallback if parsing still fails\n    return {\n        \"methodology\": raw,\n        \"data\": \"Not clearly specified\",\n        \"finding\": \"Not clearly specified\",\n        \"limitations\": \"Not clearly specified\",\n    }\n\n\ndef download_pdf(url: str, dest_dir: pathlib.Path) -&gt; pathlib.Path:\n    \"\"\"Download a PDF to dest_dir, return path. Simple and naive.\"\"\"\n    fn = dest_dir / (url.rstrip(\"/\").split(\"/\")[-1] + \".pdf\" if not url.endswith(\".pdf\") else url.split(\"/\")[-1])\n    with requests.get(url, stream=True, timeout=60) as r:\n        r.raise_for_status()\n        with open(fn, \"wb\") as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n    return fn\n\n\nfrom pypdf import PdfReader\n\ndef extract_pdf_text(pdf_path: pathlib.Path, max_pages: int = 10) -&gt; str:\n    \"\"\"Crude text extraction using pypdf (first max_pages).\"\"\"\n    text = []\n    reader = PdfReader(str(pdf_path))\n    for i, page in enumerate(reader.pages):\n        if i &gt;= max_pages:\n            break\n        try:\n            text.append(page.extract_text() or \"\")\n        except Exception:\n            pass\n    return \"\\n\".join(text)",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "03_literature_review.html#fetch-data-via-arxiv-api",
    "href": "03_literature_review.html#fetch-data-via-arxiv-api",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "We will query the ArXiv API for works matching a keyword (e.g., ‚Äúquantum batteries‚Äù). ArXiv provides abstracts and metadata like publication year.\n‚ö†Ô∏è Network note: This requires internet access. If running on an offline HPC, pre-fetch and cache JSON responses.\n\nquery = \"quantum batteries\"  # change freely\ndf = search_arxiv(query, max_results=10)\nprint(f\"Fetched {len(df)} results for query: {query!r}\")\ndf.head(5)\n\nFetched 10 results for query: 'quantum batteries'\n\n\n\n\n\n\n\n\n\ntitle\nsummary\npublished\nlink\npdf\nauthors\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\n2024-05-06\n\nhttp://arxiv.org/pdf/2405.03093v1\nTinggui Zhang, Hong Yang, Shao-Ming Fei\n\n\n1\nEntanglement and energy transportation in the ...\nQuantum battery exploits the principle of quan...\n2025-02-11\n\nhttp://arxiv.org/pdf/2502.07513v1\nFan Liu, Hui-Yu Yang, Shuai-Li Wang, Jun-Zhong...\n\n\n2\nHigh-performance Kerr quantum battery\nWe propose and investigate the performance of ...\n2023-05-04\n\nhttp://arxiv.org/pdf/2305.03202v2\nMuhammad Shoufie Ukhtary, Ahmad R. T. Nugraha,...\n\n\n3\nDual-cavity controllable quantum battery\nWith the rapid development of quantum science ...\n2024-06-10\n\nhttp://arxiv.org/pdf/2406.06383v2\nDayang Zhang, Shuangquan Ma, Yunxiu Jiang, You...\n\n\n4\nOptimizing quantum battery performance by redu...\nQuantum batteries have emerged as promising de...\n2025-05-12\n\nhttp://arxiv.org/pdf/2505.08029v1\nRohit Kumar Shukla, Rajiv Kumar, Ujjwal Sen, S...",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "03_literature_review.html#summarise-a-single-abstract",
    "href": "03_literature_review.html#summarise-a-single-abstract",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "üß© Summarise a single abstract with Llama-3 70B\nNow we connect to the Groq API (OpenAI-compatible) and ask Llama-3 70B to produce a concise summary of one abstract.\n‚ö†Ô∏è Remember, if you restart the kernel, you must re-set your API key.\n\n\nabstract = df.loc[0, \"summary\"]\nclear_chat()  # start fresh\nshort_sum = summarise_abstract(abstract, topic=query)\nstructs = extract_structured_info(abstract)\nprint(short_sum)\nprint(structs)\n\nResearchers investigated methods to enhance the capacity of quantum batteries, a crucial aspect for their potential applications. They focused on bipartite quantum systems and explored the effect of local projective measurements on a subsystem of the quantum state. Using two-qubit Bell-diagonal states and X-type states as examples, the study found that local projective measurements can improve the quantum battery capacity for both the whole system and a subsystem. The theoretical findings aim to provide guidance for the experimental development of quantum batteries with improved capacity.\n{'methodology': 'Local projective measurements on bipartite quantum systems', 'data': 'Two-qubit Bell-diagonal and X-type states', 'finding': 'Local measurements can improve quantum battery capacity', 'limitations': 'Theoretical analysis, experimental development needed'}",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "03_literature_review.html#batch-summarisation-structured-extraction",
    "href": "03_literature_review.html#batch-summarisation-structured-extraction",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "Loop over all abstracts to create a summary_llm and structured columns.\nWhat this cell does: - Iterates over the rows. - Calls the LLM for a 3-4 sentence summary. - Stores the result in a new summary column. - creates a jason output that contains: ‚Äúmethodology‚Äù:, ‚Äúdata‚Äù, ‚Äúfinding‚Äù and ‚Äúlimitations‚Äù. - Stores the result in a new structured column.\n\nsummaries = []\nstructs = []\nfor i, row in df.iterrows():\n    clear_chat()\n    s = summarise_abstract(row[\"summary\"], topic=query)\n    summaries.append(s)\n\n    clear_chat()\n    st = extract_structured_info(row[\"summary\"])\n    structs.append(st)\n    time.sleep(0.2)  # be gentle\n\n    print(f\"Processed {i}/{len(df)}\")\n\n\ndf[\"summary_llm\"] = summaries\ndf[\"structured\"] = structs\n\n\n\nProcessed 0/10\nProcessed 1/10\nProcessed 2/10\nProcessed 3/10\nProcessed 4/10\nProcessed 5/10\nProcessed 6/10\nProcessed 7/10\nProcessed 8/10\nProcessed 9/10\n\n\n\ndf.head(3)\n\n\n\n\n\n\n\n\ntitle\nsummary\npublished\nlink\npdf\nauthors\nsummary_llm\nstructured\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\n2024-05-06\n\nhttp://arxiv.org/pdf/2405.03093v1\nTinggui Zhang, Hong Yang, Shao-Ming Fei\nThis study explores methods to enhance the cap...\n{'methodology': 'Local projective measurements...\n\n\n1\nEntanglement and energy transportation in the ...\nQuantum battery exploits the principle of quan...\n2025-02-11\n\nhttp://arxiv.org/pdf/2502.07513v1\nFan Liu, Hui-Yu Yang, Shuai-Li Wang, Jun-Zhong...\nResearchers studied the central-spin quantum b...\n{'methodology': 'Invariant subspace method', '...\n\n\n2\nHigh-performance Kerr quantum battery\nWe propose and investigate the performance of ...\n2023-05-04\n\nhttp://arxiv.org/pdf/2305.03202v2\nMuhammad Shoufie Ukhtary, Ahmad R. T. Nugraha,...\nResearchers propose a \"Kerr quantum battery\" c...\n{'methodology': 'Proposed and investigated a h...",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "03_literature_review.html#quick-counts-simple-visualisation",
    "href": "03_literature_review.html#quick-counts-simple-visualisation",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "# Count by year (based on 'published' YYYY-MM-DD -&gt; YYYY)\nyears = df[\"published\"].str.slice(0,4)\ncounts = years.value_counts().sort_index()\ncounts.plot(kind=\"bar\")\nplt.title(\"Papers per Year (arXiv results)\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Count\")\nplt.show()",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "03_literature_review.html#finding-most-relevant-papers-and-download-pdfs-and-extract-crude-text",
    "href": "03_literature_review.html#finding-most-relevant-papers-and-download-pdfs-and-extract-crude-text",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "import json, time, textwrap\n\ndef select_and_fetch_pdfs(\n    df: pd.DataFrame,\n    question: str,\n    k: int = 3,\n    max_pages: int = 8,\n    sleep_s: float = 0.5,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Use the LLM to select the k most relevant entries in df for the research question,\n    download their PDFs, extract crude text, and return a df_top with added columns:\n      - pdf_file\n      - crude_text\n\n    Requires: chat(), set_system(), clear_chat(), download_pdf(), extract_pdf_text(),\n              DATA_DIR (Path) to exist.\n    \"\"\"\n    assert {\"title\", \"summary\", \"link\", \"pdf\"}.issubset(df.columns), \"df must have title, summary, link, pdf\"\n\n    # 1) Prepare a short list for the model (index, title, short summary)\n    items = []\n    for i, row in df.iterrows():\n        t = str(row[\"title\"]).strip()\n        s = str(row[\"summary\"]).strip().replace(\"\\n\", \" \")\n        s = (s[:300] + \"‚Ä¶\") if len(s) &gt; 300 else s  # keep prompt small\n        items.append({\"idx\": int(i), \"title\": t, \"summary\": s})\n\n    shortlist = json.dumps(items, ensure_ascii=False)\n\n    # 2) Ask the model to return ONLY JSON with a list of the best indices\n    clear_chat()\n    set_system(\"Return ONLY valid JSON. No extra text or code fences.\")\n    prompt = f\"\"\"\nYou are selecting the most relevant papers for a research question.\n\nQUESTION:\n{question}\n\nHere is a list of candidates (index, title, summary):\n{shortlist}\n\nReturn ONLY JSON with this exact shape:\n{{\"best\": [idx1, idx2, ...]}}\n\nRules:\n- Choose exactly {k} unique indices.\n- Prefer titles/summaries that directly address the question.\n- Do not add explanations or extra keys.\n\"\"\"\n    raw = chat(textwrap.dedent(prompt).strip(), temperature=0.0)\n\n    # 3) Parse indices; simple fence stripping just in case\n    cleaned = raw.strip().removeprefix(\"```json\").removeprefix(\"```\").removesuffix(\"```\").strip()\n    try:\n        obj = json.loads(cleaned)\n        idxs = list(dict.fromkeys([int(x) for x in obj.get(\"best\", [])]))[:k]  # unique, max k\n    except Exception:\n        idxs = list(df.index)[:k]  # fallback: take head(k)\n\n    if len(idxs) &lt; k:\n        # pad with head(k) if model returned fewer than k\n        head_idxs = [i for i in df.index[:k] if i not in idxs]\n        idxs = (idxs + head_idxs)[:k]\n\n    # 4) Download PDFs and extract text\n    pdf_dir = DATA_DIR / \"full_texts\"\n    pdf_dir.mkdir(parents=True, exist_ok=True)\n\n    rows = []\n    for i in idxs:\n        row = df.loc[i]\n        url = row[\"pdf\"] or row[\"link\"]\n        pdf_name, crude = \"\", \"\"\n        if url:\n            try:\n                path = download_pdf(url, pdf_dir)\n                pdf_name = path.name\n                crude = extract_pdf_text(path, max_pages=max_pages)\n            except Exception as e:\n                print(f\"Failed for idx {i}: {e}\")\n        rows.append({**row.to_dict(), \"pdf_file\": pdf_name, \"crude_text\": crude})\n        time.sleep(sleep_s)\n\n    df_top = pd.DataFrame(rows).reset_index(drop=True)\n    return df_top\n\n\nquestion = \"What experimental or theoretical methods advance quantum batteries most effectively?\"\ndf_top = select_and_fetch_pdfs(df, question, k=3, max_pages=8)\ndf_top.head(3)\n\n\n\n\n\n\n\n\ntitle\nsummary\npublished\nlink\npdf\nauthors\nsummary_llm\nstructured\npdf_file\ncrude_text\n\n\n\n\n0\nLocal-projective-measurement-enhanced quantum ...\nQuantum batteries have significant potential a...\n2024-05-06\n\nhttp://arxiv.org/pdf/2405.03093v1\nTinggui Zhang, Hong Yang, Shao-Ming Fei\nThis study explores methods to enhance the cap...\n{'methodology': 'Local projective measurements...\n2405.03093v1.pdf\narXiv:2405.03093v1 [quant-ph] 6 May 2024\\nLo...\n\n\n1\nOptimizing quantum battery performance by redu...\nQuantum batteries have emerged as promising de...\n2025-05-12\n\nhttp://arxiv.org/pdf/2505.08029v1\nRohit Kumar Shukla, Rajiv Kumar, Ujjwal Sen, S...\nResearchers investigated the dynamics of quant...\n{'methodology': 'Investigating interplay betwe...\n2505.08029v1.pdf\narXiv:2505.08029v1 [quant-ph] 12 May 2025\\nO...\n\n\n2\nEfficient charging of multiple open quantum ba...\nWe explore a protocol that efficiently charges...\n2024-10-25\n\nhttp://arxiv.org/pdf/2410.19303v1\nJosephine Dias, Hui Wang, Kae Nemoto, Franco N...\nThis study aims to develop an efficient protoc...\n{'methodology': 'protocol using collective cou...\n2410.19303v1.pdf\nEfficient charging of multiple open quantum ba...\n\n\n\n\n\n\n\n\n\n\n\nInstead of asking the LLM directly, each abstract and the research question can be converted into vector embeddings using a sentence or document encoder (e.g., Sentence-Transformers, OpenAI text-embedding-3-small, or Groq‚Äôs embedding models*).\nRelevance is then computed via cosine similarity, and the top-K most similar abstracts are selected.\n\nPros: Fast, reproducible, and explainable.\n\nCons: Requires an embedding model.\n\nTypical use: The foundation of most RAG (Retrieval-Augmented Generation) systems.\n\n\n\n\n\nAnother approach is to define specific evaluation criteria and let the LLM (or a human reviewer) score each abstract numerically.\nFor example, score each paper from 1‚Äì5 on: - Method novelty\n- Data similarity to your question\n- Domain alignment\n- Practical applicability\nYou can then compute a weighted average or composite score to select the top-K.\nThis method is especially useful for research evaluation, grant triaging, or systematic reviews, where transparency and criteria consistency matter.",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "03_literature_review.html#save-csv-for-rag-notebook",
    "href": "03_literature_review.html#save-csv-for-rag-notebook",
    "title": "03 ‚Äî Literature Review with LLMs",
    "section": "",
    "text": "out_csv = DATA_DIR / \"literature_corpus.csv\"\ndf.to_csv(out_csv, index=False)\nprint(\"Saved:\", out_csv.resolve())\n\nout_csv = DATA_DIR / \"literature_corpus_top.csv\"\ndf_top.to_csv(out_csv, index=False)\nprint(\"Saved:\", out_csv.resolve())\n\nSaved: C:\\code\\llm_tutorial\\literature_data\\literature_corpus.csv\nSaved: C:\\code\\llm_tutorial\\literature_data\\literature_corpus_top.csv\n\n\n\n\n\nYou fetched paper metadata into a DataFrame.\nYou used chat() with a resettable memory for summarisation and structured extraction.\nYou (optionally) downloaded PDFs and extracted crude text.\nYou saved literature_corpus.csv for the next RAG notebook.",
    "crumbs": [
      "03_literature_review"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html",
    "href": "05_code_and_data_prep.html",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "",
    "text": "Goal: Practice using an LLM to help with coding and data wrangling tasks, while keeping your workflow transparent and reproducible.\nWhat you‚Äôll learn: - When LLMs are helpful for coding ‚Äî and when they are not. - Generating a small Python function from natural language (NL). - Explaining existing code in plain English. - Cleaning a tiny messy dataset with clear, auditable steps. - Asking quick statistical questions (and verifying with code).",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#groq-api-settings-run-first",
    "href": "05_code_and_data_prep.html#groq-api-settings-run-first",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "0) Groq API settings (run first)",
    "text": "0) Groq API settings (run first)\nPaste your Groq API key below. For a workshop, it‚Äôs fine to use a plain string here (but not secure for sharing).\n\n# --- Groq API Settings ---\nimport os\nos.environ[\"GROQ_API_KEY\"] = \"\"  # &lt;-- replace with your key, e.g., \"gsk_...\"\nmodel = \"llama-3.3-70b-versatile\"  # https://console.groq.com/docs/models\nos.environ[\"BASE_URL\"] = \"https://api.groq.com/openai/v1\"  # OpenAI-compatible endpoint\nprint(\"Groq settings ready (remember to paste your key).\")\n\nGroq settings ready (remember to paste your key).",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#create-the-client-and-helpers",
    "href": "05_code_and_data_prep.html#create-the-client-and-helpers",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "1) Create the client and helpers",
    "text": "1) Create the client and helpers\nWe use a small set of helpers: - chat() ‚Äî send a message to the model. - set_system() ‚Äî reset memory with a system instruction. - clear_chat() ‚Äî clear memory entirely.\nKeeping memory tidy is important for reproducibility.\n\nfrom openai import OpenAI\n\nchat_history = []\nclient = OpenAI(api_key=os.environ[\"GROQ_API_KEY\"], base_url=os.environ[\"BASE_URL\"])\n\ndef set_system(prompt: str):\n    \"\"\"Reset chat to a single system message.\"\"\"\n    global chat_history\n    chat_history = [{\"role\": \"system\", \"content\": prompt}]\n    return chat_history\n\ndef clear_chat():\n    \"\"\"Clear all chat history.\"\"\"\n    global chat_history\n    chat_history = []\n    return chat_history\n\ndef chat(user_input: str, temperature: float = 0.2, max_turns: int = 8):\n    \"\"\"Send one user turn and get a reply, preserving context.\n    Keeps system prompt + last `max_turns` user/assistant messages.\n    \"\"\"\n    global chat_history\n    chat_history.append({\"role\": \"user\", \"content\": user_input})\n    system = chat_history[:1]\n    recent = chat_history[-(max_turns*2):] if len(chat_history) &gt; 1 else []\n    window = system + recent\n    resp = client.chat.completions.create(model=model, messages=window, temperature=temperature)\n    reply = resp.choices[0].message.content\n    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n    return reply\n\n\nprint(\"Testing API ...\")\nprint()\nprint(\"User:\")\nprint(\"Hello LLM!\")\nprint(\"LLM:\")\nprint(chat(\"Hello LLM!\"))\nprint()\nprint(\"Client ready. Use chat('...'), set_system('...'), clear_chat().\")\n\n\nTesting API ...\n\nUser:\nHello LLM!\nLLM:\nHello! It's nice to meet you. Is there something I can help you with or would you like to chat?\n\nClient ready. Use chat('...'), set_system('...'), clear_chat().",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#when-to-use-llms-for-coding-and-when-not-to",
    "href": "05_code_and_data_prep.html#when-to-use-llms-for-coding-and-when-not-to",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "2) When to use LLMs for coding ‚Äî and when not to",
    "text": "2) When to use LLMs for coding ‚Äî and when not to\nGood uses: - Writing small helper functions (string cleaning, quick plotting, file I/O). - Explaining unknown code you already trust. - Drafting boilerplate (docstrings, argument parsing).\nBe cautious / avoid: - Security-sensitive code (auth, crypto, secrets). - Heavy numerical code where correctness is critical (derive first, then code). - Blindly executing generated code ‚Äî always read and test.\nIn this notebook, we keep examples small and auditable.",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#generate-a-small-python-function-from-natural-language-nl",
    "href": "05_code_and_data_prep.html#generate-a-small-python-function-from-natural-language-nl",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "3) Generate a small Python function from natural language (NL)",
    "text": "3) Generate a small Python function from natural language (NL)\nWe‚Äôll ask the LLM for a short, reusable helper: &gt; ‚ÄúWrite a function that normalises a CSV column (strip spaces, lowercase strings, and convert numbers safely).‚Äù\nWe do not auto-execute the returned code ‚Äî we read it first, then (optionally) paste it into a new cell.\n\nclear_chat()\nset_system(\"You are a helpful Python tutor. Keep code short, readable, and beginner-friendly.\")\n\nprompt = \"\"\"    Write a Python function:\n- name: normalize_column(df, col)\n- if the column is string-like: strip spaces and lowercase\n- if numeric-like: coerce to numeric (errors='coerce')\n- return the modified dataframe (in-place ok for simplicity)\nKeep it short and add a concise docstring.\n\"\"\"\ncode_suggestion = chat(prompt, temperature=0.2)\nprint(code_suggestion)\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndef normalize_column(df, col):\n    \"\"\"\n    Normalize a column in a DataFrame: strip and lowercase strings, coerce to numeric otherwise.\n\n    Parameters:\n    df (pd.DataFrame): Input DataFrame\n    col (str): Column name to normalize\n\n    Returns:\n    pd.DataFrame: Modified DataFrame\n    \"\"\"\n    if df[col].dtype.kind in 'bOUS':  # string-like\n        df[col] = df[col].str.strip().str.lower()\n    else:  # numeric-like\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    return df\n```\n\n\nReview the code above (visually) and paste it into a new cell if you‚Äôre happy with it.\nFor convenience, here‚Äôs a simple reference implementation you can run directly:\n\nimport pandas as pd\nimport numpy as np\n\ndef normalize_column(df: pd.DataFrame, col: str) -&gt; pd.DataFrame:\n    \"\"\"Normalize a column: strip/lowercase strings, coerce numeric.\n\n\n    This is a minimal, workshop-friendly version.\n    \"\"\"\n    if col not in df.columns:\n        return df\n    s = df[col]\n    # Try numeric coercion first\n    coerced = pd.to_numeric(s, errors=\"coerce\")\n    if coerced.notna().sum() &gt; 0 and coerced.isna().sum() &lt; len(s):\n        df[col] = coerced\n        return df\n    # Fall back to string normalization\n    df[col] = s.astype(str).str.strip().str.lower()\n    return df\n\n# Tiny demo\ntmp = pd.DataFrame({\n    \"name\": [\"  Alice \", \"BOB\", None],\n    \"age\": [\" 23\", \"not a number\", \"45 \"],\n})\nprint(\"Before:\\n\", tmp)\nnormalize_column(tmp, \"name\")\nnormalize_column(tmp, \"age\")\nprint(\"\\nAfter:\\n\", tmp)\n\nBefore:\n        name           age\n0    Alice             23\n1       BOB  not a number\n2      None           45 \n\nAfter:\n     name   age\n0  alice  23.0\n1    bob   NaN\n2   none  45.0",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#explain-existing-code",
    "href": "05_code_and_data_prep.html#explain-existing-code",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "4) Explain existing code",
    "text": "4) Explain existing code\nNow let‚Äôs ask the LLM to explain a snippet. This is great for onboarding and code reviews.\n\nsnippet = \"\"\"    def zscore(x):\n    import numpy as np\n    x = np.asarray(x, dtype=float)\n    return (x - x.mean()) / (x.std(ddof=1) if x.size &gt; 1 else 1.0)\n\"\"\"\n\nclear_chat()\nset_system(\"Explain code like a patient senior engineer helping a beginner.\")\nexplanation = chat(f\"Explain this code step by step:\\n\\n{snippet}\", temperature=0.2)\nprint(explanation)\n\nLet's break down this code step by step.\n\n### Function Definition\n```python\ndef zscore(x):\n```\nThis line defines a function named `zscore` that takes one argument `x`. This function will calculate the z-score of the input data.\n\n### Importing Libraries\n```python\nimport numpy as np\n```\nThis line imports the `numpy` library and assigns it the alias `np`. `numpy` is a library for efficient numerical computation in Python.\n\n### Data Conversion\n```python\nx = np.asarray(x, dtype=float)\n```\nThis line converts the input `x` into a `numpy` array with a data type of `float`. This is done to ensure that the input data is in a format that can be used for numerical computations.\n\n### Calculating the Z-Score\n```python\nreturn (x - x.mean()) / (x.std(ddof=1) if x.size &gt; 1 else 1.0)\n```\nThis line calculates the z-score of the input data and returns the result. Let's break it down further:\n\n* `x.mean()`: This calculates the mean (average) of the input data.\n* `x - x.mean()`: This subtracts the mean from each data point, which gives us the deviation of each point from the mean.\n* `x.std(ddof=1)`: This calculates the standard deviation of the input data. The `ddof=1` argument specifies that we want to use Bessel's correction, which is a way of estimating the population standard deviation from a sample.\n* `x.size &gt; 1`: This checks if the input data has more than one element. If it does, we use the standard deviation to calculate the z-score. If it doesn't, we use a default value of 1.0 to avoid division by zero.\n* `(x - x.mean()) / (x.std(ddof=1) if x.size &gt; 1 else 1.0)`: This divides the deviation of each point from the mean by the standard deviation (or 1.0 if the input data has only one element). This gives us the z-score, which is a measure of how many standard deviations each point is away from the mean.\n\n### Example Use Case\n```python\ndata = [1, 2, 3, 4, 5]\nz_scores = zscore(data)\nprint(z_scores)\n```\nThis code would calculate the z-score of each point in the input data and print the result.\n\n### Advice\nWhen working with this code, make sure to pass in a list or array of numbers as the input `x`. Also, be aware that the z-score calculation assumes that the input data is normally distributed. If the data is not normally distributed, you may need to use a different method to calculate the z-score.",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#data-cleaning-with-guidance",
    "href": "05_code_and_data_prep.html#data-cleaning-with-guidance",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "5) Data cleaning with guidance",
    "text": "5) Data cleaning with guidance\nWe‚Äôll make a tiny messy dataset and demonstrate a few small, auditable cleaning steps.\nSteps: 1. Inspect data (head, dtypes, missing values). 2. Normalise columns using our helper. 3. Handle missing values with simple choices. 4. Fix simple typos using a small dictionary.\n\n# Create a tiny messy dataset\nraw = pd.DataFrame({\n    \"id\": [1, 2, 3, 4, 5],\n    \"city\": [\"Brisbane\", \"brisbane \", \"Brisban\", None, \"Sydney\"],\n    \"temp_c\": [\"22.1\", \"21.8\", \"not avail\", \" 19.5\", \"  28.0 \"],\n    \"notes\": [\" Sunny\", \"Cloudy\", None, \" light rain\", \"WINDY  \"],\n})\n\nprint(\"Original data:\")\ndisplay(raw)\n\nprint(\"Dtypes:\")\nprint(raw.dtypes)\n\nOriginal data:\n\n\n\n\n\n\n\n\n\nid\ncity\ntemp_c\nnotes\n\n\n\n\n0\n1\nBrisbane\n22.1\nSunny\n\n\n1\n2\nbrisbane\n21.8\nCloudy\n\n\n2\n3\nBrisban\nnot avail\nNone\n\n\n3\n4\nNone\n19.5\nlight rain\n\n\n4\n5\nSydney\n28.0\nWINDY\n\n\n\n\n\n\n\nDtypes:\nid         int64\ncity      object\ntemp_c    object\nnotes     object\ndtype: object\n\n\n\nNormalising columns\n\n# 5.1 Normalize textual/numeric columns\nclean1 = raw.copy()\nclean1 = normalize_column(clean1, \"temp_c\")\nclean1 = normalize_column(clean1, \"notes\")\n# for 'city', keep as strings (no numeric coercion), so do a custom string pass:\nclean1[\"city\"] = clean1[\"city\"].astype(str).str.strip().str.lower()\n\nprint(\"After basic normalization:\")\ndisplay(clean1)\nprint(clean1.dtypes)\n\nAfter basic normalization:\n\n\n\n\n\n\n\n\n\nid\ncity\ntemp_c\nnotes\n\n\n\n\n0\n1\nbrisbane\n22.1\nsunny\n\n\n1\n2\nbrisbane\n21.8\ncloudy\n\n\n2\n3\nbrisban\nNaN\nnone\n\n\n3\n4\nnone\n19.5\nlight rain\n\n\n4\n5\nsydney\n28.0\nwindy\n\n\n\n\n\n\n\nid          int64\ncity       object\ntemp_c    float64\nnotes      object\ndtype: object\n\n\n\n\nHandle missing values\nExample function to compare with LLm‚Äôs code\n\ndef fill_missing_auto(df, placeholder=\"unknown\"):\n    \"\"\"\n    Fill missing values automatically:\n      - Numeric columns ‚Üí replace NaN with the column mean\n      - Text columns ‚Üí replace 'none' with missing, then fill with a placeholder\n\n    Returns a new DataFrame (does not change the original).\n    \"\"\"\n    out = df.copy()\n\n    for col in out.columns:\n        if out[col].dtype.kind in \"fiu\":  # numeric columns\n            mean_val = out[col].mean(skipna=True)\n            out[col] = out[col].fillna(mean_val)\n        elif out[col].dtype.kind in \"bOUS\":  # boolean or text-like\n            out[col] = out[col].replace({\"none\": None}).fillna(placeholder)\n\n    return out\n\n\nAsking LLM to generate the function\n\n### Ask LLM to generate the function\n\nclear_chat()\nset_system(\"You are a helpful Python tutor. Keep code short, readable, and beginner-friendly.\")\n\nprompt = \"\"\"\nCreate a function named fill_missing_auto that performs below.\nIt gets a dataframe, and a place holder string (default \"unknown\"). It detects string and numerical values and fills in \nmissing values using a simple, easy-to-read approach:\n  - For the numeric columns replaces NaN values with the column mean.\n  - For text columns turns 'none' into missing, then fills missing entries with the placeholder (default \"unknown\").\nReturns a new DataFrame (does not modify the original).\n\"\"\"\n\ncode_suggestion = chat(prompt, temperature=0.2)\nprint(code_suggestion)\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndef fill_missing_auto(df, placeholder=\"unknown\"):\n    \"\"\"\n    Fill missing values in a DataFrame.\n\n    For numeric columns, replace NaN values with the column mean.\n    For text columns, replace 'none' with NaN, then fill NaN values with the placeholder.\n\n    Args:\n        df (pd.DataFrame): Input DataFrame.\n        placeholder (str, optional): Placeholder string. Defaults to \"unknown\".\n\n    Returns:\n        pd.DataFrame: New DataFrame with filled missing values.\n    \"\"\"\n\n    # Create a copy of the original DataFrame to avoid modifying it\n    new_df = df.copy()\n\n    # Iterate over each column in the DataFrame\n    for col in new_df.columns:\n        # Check if the column contains numeric values\n        if new_df[col].dtype.kind in 'bifc':\n            # Replace NaN values with the column mean\n            new_df[col] = new_df[col].fillna(new_df[col].mean())\n        else:\n            # Replace 'none' with NaN\n            new_df[col] = new_df[col].replace('none', np.nan)\n            # Fill NaN values with the placeholder\n            new_df[col] = new_df[col].fillna(placeholder)\n\n    return new_df\n\n# Example usage:\ndf = pd.DataFrame({\n    'A': [1, 2, np.nan, 4],\n    'B': ['a', 'b', 'none', 'd'],\n    'C': [np.nan, 2.5, 3.5, 4.5]\n})\n\nnew_df = fill_missing_auto(df)\nprint(new_df)\n```\n\nIn this code:\n\n1. We define a function `fill_missing_auto` that takes a DataFrame `df` and a placeholder string as input.\n2. We create a copy of the original DataFrame to avoid modifying it.\n3. We iterate over each column in the DataFrame.\n4. For numeric columns, we replace NaN values with the column mean using `fillna` and `mean` methods.\n5. For text columns, we replace 'none' with NaN using the `replace` method, then fill NaN values with the placeholder using `fillna`.\n6. Finally, we return the new DataFrame with filled missing values.\n\nThe example usage demonstrates how to use the `fill_missing_auto` function with a sample DataFrame.\n\n\nPaste LLMs function below\n\ndef fill_missing_auto(df, placeholder=\"unknown\"):\n    \"\"\"\n    Fill missing values in a DataFrame.\n\n    For numeric columns, replace NaN values with the column mean.\n    For text columns, replace 'none' with NaN, then fill NaN values with the placeholder.\n\n    Args:\n        df (pd.DataFrame): Input DataFrame.\n        placeholder (str, optional): Placeholder string. Defaults to \"unknown\".\n\n    Returns:\n        pd.DataFrame: New DataFrame with filled missing values.\n    \"\"\"\n\n    # Create a copy of the original DataFrame\n    new_df = df.copy()\n\n    # Iterate over each column in the DataFrame\n    for col in new_df.columns:\n        # Check if the column contains numeric values\n        if new_df[col].dtype.kind in 'bifc':\n            # Replace NaN values with the column mean\n            new_df[col] = new_df[col].fillna(new_df[col].mean())\n        else:\n            # Replace 'none' with NaN\n            new_df[col] = new_df[col].replace('none', np.nan)\n            # Replace NaN values with the placeholder\n            new_df[col] = new_df[col].fillna(placeholder)\n\n    return new_df\n\nTesting the function\n\n# 5.2 Handle missing values (with helper)\nclean2 = fill_missing_auto(clean1, placeholder=\"unknown\")\n\nprint(\"After filling missing values:\")\ndisplay(clean2)\n\nAfter filling missing values:\n\n\n\n\n\n\n\n\n\nid\ncity\ntemp_c\nnotes\n\n\n\n\n0\n1\nbrisbane\n22.10\nsunny\n\n\n1\n2\nbrisbane\n21.80\ncloudy\n\n\n2\n3\nbrisban\n22.85\nunknown\n\n\n3\n4\nunknown\n19.50\nlight rain\n\n\n4\n5\nsydney\n28.00\nwindy\n\n\n\n\n\n\n\n\n\nFix typos\nExample dictionary to fix typos\n\ncity_fix = {\"brisban\": \"brisbane\", \"brisbane \": \"brisbane\"}\n\nAsking LLM to make the dictionary\n\nprompt\n\n'\\nCreate a function named fill_missing_auto that performs below.\\nIt gets a dataframe, and a place holder string (default \"unknown\"). It detects string and numerical values and fills in \\nmissing values using a simple, easy-to-read approach:\\n  - For the numeric columns replaces NaN values with the column mean.\\n  - For text columns turns \\'none\\' into missing, then fills missing entries with the placeholder (default \"unknown\").\\nReturns a new DataFrame (does not modify the original).\\n'\n\n\n\n### Ask LLM to generate the dictionary\n\nclear_chat()\nset_system(\"You are a helpful Python tutor. Keep code short, readable, and beginner-friendly.\")\n\n\ncolumn_unique_str = str(raw.city.unique())\nprompt = f\"\"\"\nGive me a dictionary to use for replacing and fixing the misspellings and typos in this list: {column_unique_str}\n\"\"\"\n\ncode_suggestion = chat(prompt, temperature=0.2)\nprint(code_suggestion)\n\nHere's a dictionary that maps common misspellings and typos to their correct spellings:\n\n```python\ncity_corrections = {\n    'Brisban': 'Brisbane',\n    'brisbane': 'Brisbane',  # to standardize case\n    'brisban': 'Brisbane',  # another possible typo\n    'sydney': 'Sydney',  # to standardize case\n}\n```\n\nYou can use this dictionary to replace the misspellings and typos in your list. Note that this dictionary does not handle the `None` value, as it's not a string that can be corrected. You may want to add a separate check to handle `None` values. \n\nHere's a simple example of how you could use this dictionary:\n\n```python\ncity_list = ['Brisbane', 'brisbane', 'Brisban', None, 'Sydney']\n\ncorrected_list = []\nfor city in city_list:\n    if city is None:\n        corrected_list.append(None)  # or some other default value\n    else:\n        corrected_list.append(city_corrections.get(city, city))\n\nprint(corrected_list)\n```\n\n\nPaste the dictionary proposed by the LLM below\n\ncity_fix = {\n    'brisbane': 'Brisbane',\n    'brisban': 'Brisbane',\n    'sydney': 'Sydney'\n}\n\nTesting the dictionary\n\n# 5.3 Fix simple typos using a dictionary\nclean3 = clean2.copy()\nclean3[\"city\"] = clean2[\"city\"].replace(city_fix)\n\nprint(\"Final cleaned dataset:\")\ndisplay(clean3)\n\nFinal cleaned dataset:\n\n\n\n\n\n\n\n\n\nid\ncity\ntemp_c\nnotes\n\n\n\n\n0\n1\nBrisbane\n22.10\nsunny\n\n\n1\n2\nBrisbane\n21.80\ncloudy\n\n\n2\n3\nBrisbane\n22.85\nunknown\n\n\n3\n4\nunknown\n19.50\nlight rain\n\n\n4\n5\nSydney\n28.00\nwindy",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#quick-statistical-help",
    "href": "05_code_and_data_prep.html#quick-statistical-help",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "6) Quick statistical help",
    "text": "6) Quick statistical help\nWe‚Äôll ask the LLM which test compares two independent samples, then run the test with Python.\n\nclear_chat()\nset_system(\"You are a helpful stats tutor for beginners.\")\nq = \"What is the name of simplest statistical test to compare two independent samples when we assume normality? Pick a common multi-purpose one and explain briefly what it returns and how it does it.\"\nans = chat(q, temperature=0.0)\nprint(ans)\n\nThe simplest statistical test to compare two independent samples when we assume normality is the **Two-Sample T-Test**, also known as the Independent Samples T-Test.\n\nThis test returns a **p-value** and a **t-statistic**. The p-value indicates the probability of observing the difference between the two sample means (or a more extreme difference) assuming that the true population means are equal. The t-statistic is a measure of the number of standard errors by which the sample means differ.\n\nThe Two-Sample T-Test works by:\n\n1. Calculating the sample means and standard deviations of the two groups.\n2. Calculating the difference between the sample means.\n3. Calculating the standard error of the difference (which takes into account the sample sizes and standard deviations).\n4. Converting the difference to a t-statistic by dividing it by the standard error.\n5. Looking up the t-statistic in a t-distribution table (or using software) to find the p-value.\n\nIf the p-value is below a certain significance level (e.g., 0.05), we reject the null hypothesis that the population means are equal, and conclude that the difference between the sample means is statistically significant.\n\n\n\nq=\"\"\"\ngive me a python function that gets two arrays as input and implements this test. \nDo not import it from any other libraries. \nkeep the code very simple for educational purposes. add comments and explanations to teh code.\n\"\"\"\n\nans = chat(q, temperature=0.0)\nprint(\"Model's suggestion:\", ans)\n\nModel's suggestion: ```python\nimport math\n\ndef calculate_mean(array):\n    # Calculate the mean of an array\n    return sum(array) / len(array)\n\ndef calculate_variance(array):\n    # Calculate the variance of an array\n    mean = calculate_mean(array)\n    return sum((x - mean) ** 2 for x in array) / len(array)\n\ndef calculate_standard_deviation(array):\n    # Calculate the standard deviation of an array\n    return math.sqrt(calculate_variance(array))\n\ndef two_sample_t_test(sample1, sample2):\n    \"\"\"\n    Perform a two-sample t-test on two independent samples.\n\n    Args:\n        sample1 (list): The first sample.\n        sample2 (list): The second sample.\n\n    Returns:\n        t_statistic (float): The t-statistic.\n        p_value (float): The p-value (approximated).\n    \"\"\"\n    # Calculate the means of the two samples\n    mean1 = calculate_mean(sample1)\n    mean2 = calculate_mean(sample2)\n\n    # Calculate the standard deviations of the two samples\n    std_dev1 = calculate_standard_deviation(sample1)\n    std_dev2 = calculate_standard_deviation(sample2)\n\n    # Calculate the standard error of the difference\n    n1 = len(sample1)\n    n2 = len(sample2)\n    standard_error = math.sqrt((std_dev1 ** 2 / n1) + (std_dev2 ** 2 / n2))\n\n    # Calculate the t-statistic\n    t_statistic = (mean1 - mean2) / standard_error\n\n    # Approximate the p-value using a rough estimate (not accurate for small samples)\n    # This is a very simplified version and should not be used for real-world applications\n    degrees_of_freedom = n1 + n2 - 2\n    p_value = 2 * (1 - (math.erf(abs(t_statistic) / math.sqrt(2)) + 1) / 2)\n\n    return t_statistic, p_value\n\n# Example usage:\nsample1 = [23, 21, 19, 24, 20]\nsample2 = [17, 18, 16, 19, 15]\nt_statistic, p_value = two_sample_t_test(sample1, sample2)\nprint(f\"t-statistic: {t_statistic}, p-value: {p_value}\")\n```\n\nNote: This code is a simplified version of the two-sample t-test and should not be used for real-world applications. The p-value calculation is a rough estimate and not accurate for small samples. In practice, you should use a library like SciPy or a statistical software package to perform a two-sample t-test.\n\n\nPaste the LLM proposed function below\n\nimport math\n\ndef calculate_mean(array):\n    # Calculate the mean of an array\n    return sum(array) / len(array)\n\ndef calculate_variance(array):\n    # Calculate the variance of an array\n    mean = calculate_mean(array)\n    return sum((x - mean) ** 2 for x in array) / len(array)\n\ndef calculate_standard_deviation(array):\n    # Calculate the standard deviation of an array\n    return math.sqrt(calculate_variance(array))\n\ndef two_sample_t_test(sample1, sample2):\n    # Calculate the means of the two samples\n    mean1 = calculate_mean(sample1)\n    mean2 = calculate_mean(sample2)\n\n    # Calculate the standard deviations of the two samples\n    std_dev1 = calculate_standard_deviation(sample1)\n    std_dev2 = calculate_standard_deviation(sample2)\n\n    # Calculate the standard error of the difference\n    n1 = len(sample1)\n    n2 = len(sample2)\n    std_error = math.sqrt((std_dev1 ** 2 / n1) + (std_dev2 ** 2 / n2))\n\n    # Calculate the t-statistic\n    t_statistic = (mean1 - mean2) / std_error\n\n    # Calculate the degrees of freedom\n    df = n1 + n2 - 2\n\n    # Calculate the p-value (approximation using a normal distribution)\n    # Note: This is a simplification and not the exact p-value calculation\n    # In practice, you would use a t-distribution table or a library function\n    p_value = 2 * (1 - (math.erf(abs(t_statistic) / math.sqrt(2)) + 1) / 2)\n\n    return t_statistic, p_value\n\nTesting the function\n\n# Verify with a simple t-test example\n\nimport numpy as np\nrng = np.random.default_rng(0)\nsample1 = rng.normal(22.0, 2.5, size=30)\nsample2 = rng.normal(23.0, 2.5, size=30)\n\nt_statistic, p_value = two_sample_t_test(sample1, sample2)\nprint(f\"T-Statistic: {t_statistic}\")\nprint(f\"P-Value: {p_value}\")\n\nT-Statistic: -3.5295748922219743\nP-Value: 0.0004162278799961783",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#common-pitfalls-and-how-to-avoid-them",
    "href": "05_code_and_data_prep.html#common-pitfalls-and-how-to-avoid-them",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "7) Common pitfalls (and how to avoid them)",
    "text": "7) Common pitfalls (and how to avoid them)\n\nHallucinated imports or functions: If the model suggests a library you‚Äôve never seen, verify it exists before using it.\nSilent logic errors: Read generated code line-by-line and write tiny tests.\nMutable defaults and hidden state: Prefer pure functions that take inputs and return outputs.\nReproducibility: Save prompts, model name, and parameters (temperature, etc.) next to your code.\n\n\nRule of thumb: Treat LLM output like a junior assistant‚Äôs draft ‚Äî helpful, but requires your review.",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  },
  {
    "objectID": "05_code_and_data_prep.html#wrap-up",
    "href": "05_code_and_data_prep.html#wrap-up",
    "title": "05 ‚Äî Code & Data Prep with LLMs",
    "section": "8) Wrap-up",
    "text": "8) Wrap-up\nYou used an LLM to: - Propose a small helper function and explain code. - Clean a tiny dataset with auditable, simple steps. - Ask for a statistical test and verify with Python.\nTakeaway: LLMs can speed up everyday research coding, but you stay in control by reviewing, testing, and documenting.",
    "crumbs": [
      "05_code_and_data_prep"
    ]
  }
]