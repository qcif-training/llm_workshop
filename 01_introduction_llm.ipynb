{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "70164141",
      "metadata": {},
      "source": [
        "### Installing and checking Python packages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a32633d6",
      "metadata": {},
      "source": [
        "If have not installed packages you can uncomment the cell below to install packages.\n",
        "This is only needed once and after installation you can comment them again to stop it from running. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "716fd2b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install numpy pandas matplotlib openai requests pypdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc349c4",
      "metadata": {},
      "source": [
        "Checking installed package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ec16994e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "matplotlib              3.10.7\n",
            "matplotlib-inline       0.1.7\n",
            "numpy                   2.3.3\n",
            "openai                  2.6.0\n",
            "pandas                  2.3.3\n",
            "pypdf                   6.1.3\n",
            "requests                2.32.5\n"
          ]
        }
      ],
      "source": [
        "!pip list | findstr \"numpy pandas matplotlib openai requests pypdf\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e94bb969",
      "metadata": {},
      "source": [
        "# Introduction to Large Language Models (LLMs) for Research\n",
        "\n",
        "This notebook is the first module of a workshop on using Large Language Models (LLMs) in research workflows. It focuses on:\n",
        "\n",
        "- Setting up access to an LLM via the **Groq** API using the **OpenAI-compatible** Python client.\n",
        "- Running your **first query** and understanding the request/response structure.\n",
        "- Exploring the notion of **temperature** (randomness) in generation.\n",
        "- Creating a **continuous conversation** by keeping your own chat history.\n",
        "\n",
        "We adopt a **text-only** approach (no image/graph understanding) to ensure minimal setup and maximum reproducibility.\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "1. Configure a connection to the Groq API.\n",
        "2. Send chat messages with the OpenAI-compatible client.\n",
        "3. Control generation behaviour via `temperature`.\n",
        "4. Maintain and reuse chat history for a continuing conversation.\n",
        "\n",
        "## Background (very briefly)\n",
        "An LLM is a probabilistic model over text. Given a sequence of tokens $x_{1:t}$, it assigns probabilities to the next token $x_{t+1}$. At inference, models sample from a distribution such as\n",
        "$$p(x_{t+1}=i\\mid x_{1:t}) = \\mathrm{softmax}\\!\\left(\\frac{z_i}{T}\\right),$$\n",
        "where $z_i$ is the logit for token $i$ and $T>0$ is the **temperature**. Lower $T$ concentrates probability mass on high-logit tokens (more deterministic), while higher $T$ spreads it out (more diverse). We will **demonstrate** this behaviour below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d81cd31",
      "metadata": {},
      "source": [
        "## 1) Environment Setup\n",
        "This section prepares the Python environment. On QCIF's HPC JupyterLab image, the required package (`openai`) should already be installed. If you're running elsewhere and encounter an `ImportError`, uncomment the `%pip install` line.\n",
        "\n",
        "**What this cell does:**\n",
        "- (Optionally) installs the OpenAI Python client.\n",
        "- Imports the required modules.\n",
        "- Does **not** make any external calls yet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "22dcf842",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running outside the provided environment, uncomment the next line:\n",
        "# %pip install openai\n",
        "import os\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fac3416",
      "metadata": {},
      "source": [
        "## 2) Configure API Connection (Groq)\n",
        "LLM APIs are **stateless** web services. We'll configure a client that speaks the OpenAI-compatible protocol, pointing it to Groq's base URL.\n",
        "\n",
        "**What you'll do in this cell:**\n",
        "1. Paste your Groq API key (created at <https://console.groq.com>).\n",
        "2. Set the base URL for Groq's OpenAI-compatible endpoint.\n",
        "3. Instantiate the client.\n",
        "\n",
        "**Notes:**\n",
        "- Keep your API key private. In shared workshops, you can paste it, run this cell, and then clear the visible text.\n",
        "- You can also store keys in environment variables or use a `.env` file if preferred.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "351a8f5e",
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'os' has no attribute 'enviro'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mGROQ_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mgsk_uVDxZ6dG14ubYWqsRc18WGdyb3FYOryUw16bFTHePWjXoY6v5yti\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# <-- replace with your key.\u001b[39;00m\n\u001b[32m      4\u001b[39m model = \u001b[33m\"\u001b[39m\u001b[33mllama-3.3-70b-versatile\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Select your model https://console.groq.com/docs/models\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviro\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mBASE_URL\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mhttps://api.groq.com/openai/v1\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Groq uses an OpenAI-compatible API surface; we just change the base URL.\u001b[39;00m\n",
            "\u001b[31mAttributeError\u001b[39m: module 'os' has no attribute 'enviro'"
          ]
        }
      ],
      "source": [
        "# Paste your Groq API key below (between quotes). \n",
        "# Note this is not a secure way of entering API key because it is visible to everyone that sees your notebook.  \n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"  # <-- replace with your key.\n",
        "model = \"llama-3.3-70b-versatile\" # Select your model https://console.groq.com/docs/models\n",
        "os.environ[\"BASE_URL\"] = \"https://api.groq.com/openai/v1\" # Groq uses an OpenAI-compatible API surface; we just change the base URL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b3a825",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groq client initialized!\n"
          ]
        }
      ],
      "source": [
        "# Create the client\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    base_url=os.environ[\"BASE_URL\"],\n",
        ")\n",
        "print(\"Groq client initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d708c4dc",
      "metadata": {},
      "source": [
        "## 3) First LLM Call â€” \"Hello LLM\" (Llama-3 70B)\n",
        "Here we send a **single-turn** prompt with minimal scaffolding. The API expects a list of `messages`, where each message has a `role` and `content`.\n",
        "\n",
        "**Roles:**\n",
        "- `system`: high-level instructions (tone, persona, formatting).\n",
        "- `user`: your question or instruction.\n",
        "- `assistant`: the model's reply (the API returns this).\n",
        "\n",
        "**What this cell does:**\n",
        "- Creates a tiny conversation with `system` and `user` messages.\n",
        "- Calls the model `llama3-70b-8192` for higher-quality outputs compared to 8B.\n",
        "- Prints the model's reply.\n",
        "\n",
        "You can modify the user content and re-run to see different responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46e8bde",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Be concise.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Explain what a Large Language Model is in two sentences.\"}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    temperature=0 # lower temperature -> more deterministic\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3467cdb6",
      "metadata": {},
      "source": [
        "### Examining the response object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f44e07e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('id', 'chatcmpl-60e9c394-acc3-4abb-b0e8-a0f03fdf247a')\n",
            "('choices', [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))])\n",
            "('created', 1761253879)\n",
            "('model', 'llama-3.3-70b-versatile')\n",
            "('object', 'chat.completion')\n",
            "('service_tier', 'on_demand')\n",
            "('system_fingerprint', 'fp_4cfc2deea6')\n",
            "('usage', CompletionUsage(completion_tokens=78, prompt_tokens=57, total_tokens=135, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.17950201, prompt_time=0.004199205, completion_time=0.156019343, total_time=0.160218548))\n",
            "('usage_breakdown', None)\n",
            "('x_groq', {'id': 'req_01k89ejtxpegtvrr9b9v8ep3s6'})\n"
          ]
        }
      ],
      "source": [
        "for str in response:\n",
        "    print(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431ae070",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.choices[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2d36bd6",
      "metadata": {},
      "source": [
        "## 4) Understanding `temperature`\n",
        "The **temperature** parameter adjusts the **randomness** of token sampling. Intuitively, the model produces a probability distribution over possible next tokens from its logits $z$. The temperature rescales those logits:\n",
        "\n",
        "$$p_i = \\mathrm{softmax}\\!\\left(\\frac{z_i}{T}\\right) = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}.$$\n",
        "\n",
        "- Lower $T$ (e.g. $T=0.2$): the distribution is *sharper* around high-probability tokens, yielding more **stable** outputs.\n",
        "- Higher $T$ (e.g. $T=0.8$): the distribution is *flatter*, encouraging **diversity** and sometimes creativity.\n",
        "\n",
        "**What this cell does:**\n",
        "- Sends the *same* prompt twice, once with `temperature=0.2` and once with `temperature=0.8`.\n",
        "- Prints both answers so you can compare tone and variability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a871a61b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature: 0.2\n",
            "A Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating text based on the patterns and relationships it has learned from vast amounts of data. LLMs use complex algorithms and massive datasets to predict and create text, enabling applications such as language translation, text summarization, and conversational interfaces.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\n",
            "Temperature: 0.8\n",
            "A Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate human-like text, answer questions, and even engage in conversation, making them a powerful tool for various applications, including language translation, text summarization, and chatbots.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Describe the role of LLMs in academic research in one sentence.\"\n",
        "for temp in [0.2, 0.8]:\n",
        "    print(\"Temperature:\", temp)\n",
        "    for i in range(5):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=0 # lower temperature -> more deterministic\n",
        "        )\n",
        "        print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638df79e",
      "metadata": {},
      "source": [
        "## 5) Continuous Conversation (Keeping History)\n",
        "LLM APIs do **not** keep state between calls. To build a conversation, you keep a list of messages and send the *entire* recent history each time. We'll implement a small helper that:\n",
        "\n",
        "- Appends the user's message to a global `chat_history` list.\n",
        "- Calls the model with that history.\n",
        "- Appends the assistant's reply back into the history.\n",
        "- Returns the latest reply for display.\n",
        "\n",
        "We also keep the temperature low for focused answers. For longer chats, you can cap history to the last *k* turns to control token usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd8bf51",
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "\n",
        "def chat(user_input, temperature=0.2, max_turns=8):\n",
        "    \"\"\"Send one user turn and get a reply, preserving context.\n",
        "    - Keeps system prompt + last `max_turns` user/assistant messages.\n",
        "    \"\"\"\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Keep only the most recent `max_turns` pairs to control context size\n",
        "    system = chat_history[:1]\n",
        "    recent = chat_history[-(max_turns*2):] if len(chat_history) > 1 else []\n",
        "    window = system + recent\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=window,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    reply = resp.choices[0].message.content\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    return reply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c533697",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'role': 'system', 'content': 'Tailor your answers for a bioinformatician.'}\n",
            "{'role': 'user', 'content': 'What is logistic regression?'}\n",
            "{'role': 'assistant', 'content': '**Logistic Regression**\\n=======================\\n\\nLogistic regression is a statistical method used for binary classification problems, where the goal is to predict a binary outcome (0/1, yes/no, etc.) based on one or more predictor variables. It is a widely used technique in bioinformatics, particularly in the analysis of high-throughput data, such as gene expression or genomic variation.\\n\\n**Mathematical Formulation**\\n---------------------------\\n\\nLogistic regression models the probability of a positive outcome (e.g., disease presence) using a logistic function, also known as a sigmoid function. The logistic function maps any real-valued number to a value between 0 and 1, which represents the probability of the positive outcome.\\n\\nThe logistic regression model can be formulated as:\\n\\np = 1 / (1 + e^(-z))\\n\\nwhere:\\n\\n* p is the probability of the positive outcome\\n* e is the base of the natural logarithm\\n* z is a linear combination of the predictor variables, weighted by coefficients (Î²)\\n\\nz = Î²0 + Î²1 \\\\* x1 + Î²2 \\\\* x2 + â€¦ + Î²n \\\\* xn\\n\\nwhere:\\n\\n* Î²0 is the intercept or bias term\\n* Î²1, Î²2, â€¦, Î²n are the coefficients for each predictor variable\\n* x1, x2, â€¦, xn are the predictor variables\\n\\n**Interpretation of Coefficients**\\n-------------------------------\\n\\nThe coefficients (Î²) in logistic regression represent the change in the log-odds of the positive outcome for a one-unit change in the predictor variable, while holding all other variables constant. The odds ratio (OR) can be calculated as e^Î², which represents the multiplicative change in the odds of the positive outcome for a one-unit change in the predictor variable.\\n\\n**Common Applications in Bioinformatics**\\n-----------------------------------------\\n\\n1. **Gene expression analysis**: Logistic regression can be used to identify genes associated with a specific disease or phenotype.\\n2. **Genomic variation analysis**: Logistic regression can be used to identify genetic variants associated with a specific disease or trait.\\n3. **Protein function prediction**: Logistic regression can be used to predict the function of a protein based on its sequence or structural features.\\n4. **Classification of biological samples**: Logistic regression can be used to classify biological samples into different categories (e.g., cancer vs. normal tissue).\\n\\n**Example Code in Python**\\n---------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create logistic regression model\\nmodel = LogisticRegression()\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\nThis code snippet demonstrates how to use logistic regression to classify biological samples using the scikit-learn library in Python.'}\n",
            "{'role': 'user', 'content': 'How does it differ from linear regression?'}\n",
            "{'role': 'assistant', 'content': '**Differences between Logistic Regression and Linear Regression**\\n===========================================================\\n\\nLogistic regression and linear regression are both supervised learning algorithms used for regression tasks. However, they differ in their approach, application, and interpretation.\\n\\n**1. Outcome Variable**\\n----------------------\\n\\n* **Linear Regression**: The outcome variable is continuous, such as gene expression levels or protein concentrations.\\n* **Logistic Regression**: The outcome variable is binary (0/1, yes/no, etc.), such as disease presence or absence.\\n\\n**2. Model Formulation**\\n----------------------\\n\\n* **Linear Regression**: The model is formulated as a linear equation, where the outcome variable is a linear combination of the predictor variables.\\n\\t+ y = Î²0 + Î²1 \\\\* x1 + Î²2 \\\\* x2 + â€¦ + Î²n \\\\* xn\\n* **Logistic Regression**: The model is formulated as a logistic function, where the probability of the positive outcome is a non-linear function of the predictor variables.\\n\\t+ p = 1 / (1 + e^(-z))\\n\\t+ z = Î²0 + Î²1 \\\\* x1 + Î²2 \\\\* x2 + â€¦ + Î²n \\\\* xn\\n\\n**3. Cost Function**\\n-------------------\\n\\n* **Linear Regression**: The cost function is typically mean squared error (MSE) or mean absolute error (MAE).\\n* **Logistic Regression**: The cost function is typically cross-entropy loss or log loss.\\n\\n**4. Interpretation of Coefficients**\\n-----------------------------------\\n\\n* **Linear Regression**: The coefficients represent the change in the outcome variable for a one-unit change in the predictor variable.\\n* **Logistic Regression**: The coefficients represent the change in the log-odds of the positive outcome for a one-unit change in the predictor variable.\\n\\n**5. Assumptions**\\n-----------------\\n\\n* **Linear Regression**: Assumes linearity, independence, homoscedasticity, normality, and no multicollinearity.\\n* **Logistic Regression**: Assumes independence, no multicollinearity, and a binary outcome variable.\\n\\n**Example Code in Python**\\n---------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create linear regression model\\nlinear_model = LinearRegression()\\n\\n# Train linear model\\nlinear_model.fit(X_train, y_train)\\n\\n# Create logistic regression model\\nlogistic_model = LogisticRegression()\\n\\n# Train logistic model\\nlogistic_model.fit(X_train, (y_train > 0).astype(int))\\n\\n# Evaluate models\\nlinear_accuracy = linear_model.score(X_test, y_test)\\nlogistic_accuracy = logistic_model.score(X_test, (y_test > 0).astype(int))\\nprint(\"Linear Regression Accuracy:\", linear_accuracy)\\nprint(\"Logistic Regression Accuracy:\", logistic_accuracy)\\n```\\n\\nThis code snippet demonstrates how to use both linear regression and logistic regression to model continuous and binary outcome variables, respectively, using the scikit-learn library in Python.\\n\\n**Choosing between Linear Regression and Logistic Regression**\\n---------------------------------------------------------\\n\\n* Use linear regression when the outcome variable is continuous and the relationship between the predictor variables and the outcome variable is linear.\\n* Use logistic regression when the outcome variable is binary and the relationship between the predictor variables and the outcome variable is non-linear.'}\n"
          ]
        }
      ],
      "source": [
        "chat_history = [\n",
        "    {\"role\": \"system\", \"content\": \"Tailor your answers for a bioinformatician.\"}\n",
        "]\n",
        "\n",
        "chat(\"What is logistic regression?\")\n",
        "chat(\"How does it differ from linear regression?\")\n",
        "\n",
        "for ch in chat_history:\n",
        "    print(ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "867fad61",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'role': 'system', 'content': 'Tailor your answers for a bioinformatician.'}\n",
            "{'role': 'user', 'content': 'What is logistic regression?'}\n",
            "{'role': 'assistant', 'content': '**Logistic Regression**\\n=======================\\n\\nLogistic regression is a statistical method used for binary classification problems, where the goal is to predict a binary outcome (0/1, yes/no, etc.) based on one or more predictor variables. It is a widely used technique in bioinformatics, particularly in the analysis of high-throughput data, such as gene expression or genomic variation.\\n\\n**Mathematical Formulation**\\n---------------------------\\n\\nLogistic regression models the probability of a positive outcome (e.g., disease presence) using a logistic function, also known as a sigmoid function. The logistic function maps any real-valued number to a value between 0 and 1, which represents the probability of the positive outcome.\\n\\nThe logistic regression model can be formulated as:\\n\\np = 1 / (1 + e^(-z))\\n\\nwhere:\\n\\n* p is the probability of the positive outcome\\n* e is the base of the natural logarithm\\n* z is a linear combination of the predictor variables, weighted by coefficients (Î²)\\n\\nz = Î²0 + Î²1 \\\\* x1 + Î²2 \\\\* x2 + â€¦ + Î²n \\\\* xn\\n\\nwhere:\\n\\n* Î²0 is the intercept or bias term\\n* Î²1, Î²2, â€¦, Î²n are the coefficients for each predictor variable\\n* x1, x2, â€¦, xn are the predictor variables\\n\\n**Interpretation of Coefficients**\\n-------------------------------\\n\\nThe coefficients (Î²) in logistic regression represent the change in the log-odds of the positive outcome for a one-unit change in the predictor variable, while holding all other variables constant. The odds ratio (OR) can be calculated as e^Î², which represents the multiplicative change in the odds of the positive outcome for a one-unit change in the predictor variable.\\n\\n**Common Applications in Bioinformatics**\\n-----------------------------------------\\n\\n1. **Gene expression analysis**: Logistic regression can be used to identify genes associated with a specific disease or phenotype.\\n2. **Genomic variation analysis**: Logistic regression can be used to identify genetic variants associated with a specific disease or trait.\\n3. **Protein function prediction**: Logistic regression can be used to predict the function of a protein based on its sequence or structural features.\\n4. **Classification of biological samples**: Logistic regression can be used to classify biological samples into different categories (e.g., cancer vs. normal tissue).\\n\\n**Example Code in Python**\\n---------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create logistic regression model\\nmodel = LogisticRegression()\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\nThis code snippet demonstrates how to use logistic regression to classify biological samples using the scikit-learn library in Python.'}\n",
            "{'role': 'user', 'content': 'How does it differ from linear regression?'}\n",
            "{'role': 'assistant', 'content': '**Differences between Logistic Regression and Linear Regression**\\n===========================================================\\n\\nLogistic regression and linear regression are both supervised learning algorithms used for regression tasks. However, they differ in their approach, application, and interpretation.\\n\\n**1. Outcome Variable**\\n----------------------\\n\\n* **Linear Regression**: The outcome variable is continuous, such as gene expression levels or protein concentrations.\\n* **Logistic Regression**: The outcome variable is binary (0/1, yes/no, etc.), such as disease presence or absence.\\n\\n**2. Model Formulation**\\n----------------------\\n\\n* **Linear Regression**: The model is formulated as a linear equation, where the outcome variable is a linear combination of the predictor variables.\\n\\t+ y = Î²0 + Î²1 \\\\* x1 + Î²2 \\\\* x2 + â€¦ + Î²n \\\\* xn\\n* **Logistic Regression**: The model is formulated as a logistic function, where the probability of the positive outcome is a non-linear function of the predictor variables.\\n\\t+ p = 1 / (1 + e^(-z))\\n\\t+ z = Î²0 + Î²1 \\\\* x1 + Î²2 \\\\* x2 + â€¦ + Î²n \\\\* xn\\n\\n**3. Cost Function**\\n-------------------\\n\\n* **Linear Regression**: The cost function is typically mean squared error (MSE) or mean absolute error (MAE).\\n* **Logistic Regression**: The cost function is typically cross-entropy loss or log loss.\\n\\n**4. Interpretation of Coefficients**\\n-----------------------------------\\n\\n* **Linear Regression**: The coefficients represent the change in the outcome variable for a one-unit change in the predictor variable.\\n* **Logistic Regression**: The coefficients represent the change in the log-odds of the positive outcome for a one-unit change in the predictor variable.\\n\\n**5. Assumptions**\\n-----------------\\n\\n* **Linear Regression**: Assumes linearity, independence, homoscedasticity, normality, and no multicollinearity.\\n* **Logistic Regression**: Assumes independence, no multicollinearity, and a binary outcome variable.\\n\\n**Example Code in Python**\\n---------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create linear regression model\\nlinear_model = LinearRegression()\\n\\n# Train linear model\\nlinear_model.fit(X_train, y_train)\\n\\n# Create logistic regression model\\nlogistic_model = LogisticRegression()\\n\\n# Train logistic model\\nlogistic_model.fit(X_train, (y_train > 0).astype(int))\\n\\n# Evaluate models\\nlinear_accuracy = linear_model.score(X_test, y_test)\\nlogistic_accuracy = logistic_model.score(X_test, (y_test > 0).astype(int))\\nprint(\"Linear Regression Accuracy:\", linear_accuracy)\\nprint(\"Logistic Regression Accuracy:\", logistic_accuracy)\\n```\\n\\nThis code snippet demonstrates how to use both linear regression and logistic regression to model continuous and binary outcome variables, respectively, using the scikit-learn library in Python.\\n\\n**Choosing between Linear Regression and Logistic Regression**\\n---------------------------------------------------------\\n\\n* Use linear regression when the outcome variable is continuous and the relationship between the predictor variables and the outcome variable is linear.\\n* Use logistic regression when the outcome variable is binary and the relationship between the predictor variables and the outcome variable is non-linear.'}\n",
            "{'role': 'user', 'content': 'what are some other classification methods?'}\n",
            "{'role': 'assistant', 'content': '**Other Classification Methods**\\n=============================\\n\\nBesides logistic regression, there are several other classification methods used in bioinformatics and machine learning. Here are some of the most common ones:\\n\\n### 1. **Decision Trees**\\n\\n* **Description**: Decision trees are a type of supervised learning algorithm that uses a tree-like model to classify data.\\n* **Application**: Decision trees are useful for handling categorical data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create decision tree model\\nmodel = DecisionTreeClassifier()\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 2. **Random Forests**\\n\\n* **Description**: Random forests are an ensemble learning method that combines multiple decision trees to improve the accuracy and robustness of the model.\\n* **Application**: Random forests are useful for handling high-dimensional data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create random forest model\\nmodel = RandomForestClassifier(n_estimators=100)\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 3. **Support Vector Machines (SVMs)**\\n\\n* **Description**: SVMs are a type of supervised learning algorithm that uses a hyperplane to separate the data into different classes.\\n* **Application**: SVMs are useful for handling high-dimensional data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create SVM model\\nmodel = SVC(kernel=\"linear\")\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 4. **K-Nearest Neighbors (KNN)**\\n\\n* **Description**: KNN is a type of supervised learning algorithm that uses the k-nearest neighbors to classify new data points.\\n* **Application**: KNN is useful for handling small datasets and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create KNN model\\nmodel = KNeighborsClassifier(n_neighbors=5)\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 5. **Neural Networks**\\n\\n* **Description**: Neural networks are a type of supervised learning algorithm that uses a network of interconnected nodes (neurons) to classify data.\\n* **Application**: Neural networks are useful for handling complex, high-dimensional data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create neural network model\\nmodel = MLPClassifier(hidden_layer_sizes=(10, 10))\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\n### 6. **Gradient Boosting**\\n\\n* **Description**: Gradient boosting is an ensemble learning method that combines multiple weak models to create a strong predictive model.\\n* **Application**: Gradient boosting is useful for handling high-dimensional data and can be used for both classification and regression tasks.\\n* **Example Code in Python**:\\n```python\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load data\\ndata = pd.read_csv(\"data.csv\")\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(data.drop(\"outcome\", axis=1), data[\"outcome\"], test_size=0.2, random_state=42)\\n\\n# Create gradient boosting model\\nmodel = GradientBoostingClassifier(n_estimators=100)\\n\\n# Train model\\nmodel.fit(X_train, y_train)\\n\\n# Evaluate model\\naccuracy = model.score(X_test, y_test)\\nprint(\"Accuracy:\", accuracy)\\n```\\n\\nThese are just a few examples of the many classification methods available in bioinformatics and machine learning. The choice of method depends on the specific problem, dataset, and performance metrics.'}\n"
          ]
        }
      ],
      "source": [
        "chat(\"what are some other classification methods?\")\n",
        "\n",
        "for ch in chat_history:\n",
        "    print(ch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a049e835",
      "metadata": {},
      "source": [
        "## 8) Exercise â€” Your First Prompt\n",
        "Try your own research-related prompts. A few ideas:\n",
        "\n",
        "1. Summarise your current project in **one paragraph**.\n",
        "2. Ask for **three open research questions** in your field.\n",
        "3. Request a **draft methods paragraph** describing your dataset and analysis steps.\n",
        "\n",
        "Remember you can tweak `temperature` to trade off consistency vs creativity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d1cda6",
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_history = [\n",
        "    {\"role\": \"system\", \"content\": \"Tailor your answers for a bioinformatician.\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ace76d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As a bioinformatician, you're likely familiar with complex systems and data-driven approaches. Renewable energy policy research presents several challenges that can be broken down into the following categories:\n",
            "\n",
            "1. **Integration and Interoperability**: Renewable energy sources, such as solar and wind power, have variable output, making it challenging to integrate them into existing energy grids. This requires advanced forecasting, grid management, and energy storage systems.\n",
            "2. **Data Quality and Availability**: High-quality, granular data on energy production, consumption, and grid operations is essential for informed policy decisions. However, data gaps, inconsistencies, and lack of standardization hinder research and policy development.\n",
            "3. **Complexity and Uncertainty**: Renewable energy systems involve complex interactions between technological, economic, social, and environmental factors. Uncertainties, such as climate change and policy fluctuations, make it difficult to predict outcomes and develop effective policies.\n",
            "4. **Scalability and Spatial Analysis**: Renewable energy deployment requires consideration of spatial factors, such as land use, resource availability, and infrastructure. Scalability issues arise when trying to balance local, regional, and global energy demands with available resources.\n",
            "5. **Stakeholder Engagement and Social Acceptance**: Effective policy development requires engagement with diverse stakeholders, including communities, industries, and governments. Social acceptance of renewable energy technologies and infrastructure can be a significant challenge.\n",
            "6. **Economic and Financial Analysis**: Renewable energy policies often involve economic incentives, subsidies, and investments. Accurate economic and financial analysis is necessary to evaluate policy effectiveness, but this can be complicated by factors like technology costs, market volatility, and externalities.\n",
            "7. **Policy Frameworks and Governance**: Renewable energy policies must navigate existing regulatory frameworks, which can be inadequate or inconsistent. Effective governance structures, including international cooperation and national policies, are essential for supporting the transition to renewable energy.\n",
            "8. **Technological Innovation and Deployment**: The rapid evolution of renewable energy technologies creates challenges for policy development, as new technologies and innovations can disrupt existing markets and infrastructure.\n",
            "9. **Energy Justice and Equity**: Renewable energy policies must address issues of energy access, affordability, and equity, particularly for marginalized communities. This requires careful consideration of social and environmental impacts.\n",
            "10. **Long-term Planning and Scenario Development**: Renewable energy policy research requires long-term planning and scenario development to anticipate future energy demands, technology advancements, and potential risks.\n",
            "\n",
            "To address these challenges, researchers can employ a range of bioinformatics-inspired approaches, such as:\n",
            "\n",
            "* Data integration and analytics\n",
            "* Machine learning and predictive modeling\n",
            "* Network analysis and simulation\n",
            "* Spatial analysis and geospatial modeling\n",
            "* Stakeholder engagement and participatory modeling\n",
            "* Scenario planning and uncertainty analysis\n",
            "\n",
            "By leveraging these approaches, researchers can develop more effective renewable energy policies that balance technological, economic, social, and environmental considerations.\n"
          ]
        }
      ],
      "source": [
        "# Example: replace with your own question(s)\n",
        "print(chat(\"Summarise the challenges in renewable energy policy research.\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Wrap-Up & Next Steps\n",
        "- You configured an OpenAI-compatible client to talk to **Groq**.\n",
        "- You sent your first prompts using **Llama-3 70B** and explored the impact of `temperature`.\n",
        "- You kept conversation state locally in a Python list and learned how to save it.\n",
        "\n",
        "In the **next notebook**, we'll connect to a scholarly API to fetch abstracts and practice **literature summarisation** and **structured extraction**.\n",
        "\n",
        "**Key terms:** tokens, temperature, logits, softmax, stateless API, chat history.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
