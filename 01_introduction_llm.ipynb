{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e94bb969",
      "metadata": {},
      "source": [
        "# Introduction to Large Language Models (LLMs) for Research\n",
        "\n",
        "This notebook is the first module of a workshop on using Large Language Models (LLMs) in research workflows. It focuses on:\n",
        "\n",
        "- Setting up access to an LLM via the **Groq** API using the **OpenAI-compatible** Python client.\n",
        "- Running your **first query** and understanding the request/response structure.\n",
        "- Exploring the notion of **temperature** (randomness) in generation.\n",
        "- Creating a **continuous conversation** by keeping your own chat history.\n",
        "\n",
        "We adopt a **text-only** approach (no image/graph understanding) to ensure minimal setup and maximum reproducibility.\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "1. Configure a connection to the Groq API.\n",
        "2. Send chat messages with the OpenAI-compatible client.\n",
        "3. Control generation behaviour via `temperature`.\n",
        "4. Maintain and reuse chat history for a continuing conversation.\n",
        "\n",
        "## Background (very briefly)\n",
        "An LLM is a probabilistic model over text. Given a sequence of tokens $x_{1:t}$, it assigns probabilities to the next token $x_{t+1}$. At inference, models sample from a distribution such as\n",
        "$$p(x_{t+1}=i\\mid x_{1:t}) = \\mathrm{softmax}\\!\\left(\\frac{z_i}{T}\\right),$$\n",
        "where $z_i$ is the logit for token $i$ and $T>0$ is the **temperature**. Lower $T$ concentrates probability mass on high-logit tokens (more deterministic), while higher $T$ spreads it out (more diverse). We will **demonstrate** this behaviour below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d81cd31",
      "metadata": {},
      "source": [
        "## 1) Environment Setup\n",
        "This section prepares the Python environment. If you encounter an `ImportError`, go back to 00_setup_guid notebook to install the package.\n",
        "\n",
        "**What this cell does:**\n",
        "- Imports the OpenAI modules.\n",
        "- Does **not** make any external calls yet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "22dcf842",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running outside the provided environment, uncomment the next line:\n",
        "# %pip install openai\n",
        "import os\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fac3416",
      "metadata": {},
      "source": [
        "## 2) Configure API Connection (Groq)\n",
        "LLM APIs are **stateless** web services. We'll configure a client that speaks the OpenAI-compatible protocol, pointing it to Groq's base URL.\n",
        "\n",
        "**What you'll do in this cell:**\n",
        "1. Paste your Groq API key (to create an API key see 00_setup_guide notebook).\n",
        "2. Set the base URL for Groq's OpenAI-compatible endpoint.\n",
        "3. Instantiate the client.\n",
        "\n",
        "**Notes:**\n",
        "- Keep your API key private. In shared workshops, you can paste it, run this cell, and then clear the visible key.\n",
        "- You can also store keys in environment variables or use a `.env` file if preferred.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "351a8f5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paste your Groq API key below (between quotes). \n",
        "# Note this is not a secure way of entering API key because it is visible to everyone that sees your notebook.  \n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"  # <-- replace with your key.\n",
        "model = \"llama-3.3-70b-versatile\" # Select your model https://console.groq.com/docs/models\n",
        "os.environ[\"BASE_URL\"] = \"https://api.groq.com/openai/v1\" # Groq uses an OpenAI-compatible API surface; we just change the base URL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "98b3a825",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groq client initialized!\n"
          ]
        }
      ],
      "source": [
        "# Create the client\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    base_url=os.environ[\"BASE_URL\"],\n",
        ")\n",
        "print(\"Groq client initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d708c4dc",
      "metadata": {},
      "source": [
        "## 3) First LLM Call — \"Hello LLM\" (Llama-3 70B)\n",
        "Here we send a **single-turn** prompt with minimal scaffolding. The API expects a list of `messages`, where each message has a `role` and `content`.\n",
        "\n",
        "**Roles:**\n",
        "- `system`: high-level instructions (tone, persona, formatting).\n",
        "- `user`: your question or instruction.\n",
        "- `assistant`: the model's reply (the API returns this).\n",
        "\n",
        "**What this cell does:**\n",
        "- Creates a tiny conversation with `system` and `user` messages.\n",
        "- Calls the model `llama3 70b` for higher-quality outputs compared to 8B.\n",
        "- Prints the model's reply.\n",
        "\n",
        "You can modify the user content and re-run to see different responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e46e8bde",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate human-like text, answer questions, and even engage in conversation, making them a powerful tool for various applications such as language translation, text summarization, and chatbots.\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Be concise.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Explain what a Large Language Model is in two sentences.\"}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=messages,\n",
        "    temperature=0 # lower temperature -> more deterministic\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3467cdb6",
      "metadata": {},
      "source": [
        "### Examining the response object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f44e07e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('id', 'chatcmpl-a772b541-683b-43d6-8d91-ab34bc331aa3')\n",
            "('choices', [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate human-like text, answer questions, and even engage in conversation, making them a powerful tool for various applications such as language translation, text summarization, and chatbots.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))])\n",
            "('created', 1761507006)\n",
            "('model', 'llama-3.3-70b-versatile')\n",
            "('object', 'chat.completion')\n",
            "('service_tier', 'on_demand')\n",
            "('system_fingerprint', 'fp_55062f05af')\n",
            "('usage', CompletionUsage(completion_tokens=86, prompt_tokens=57, total_tokens=143, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.204136406, prompt_time=0.003836992, completion_time=0.204419149, total_time=0.208256141))\n",
            "('usage_breakdown', None)\n",
            "('x_groq', {'id': 'req_01k8gzznrae478nzw5x9z6rpvb'})\n"
          ]
        }
      ],
      "source": [
        "for str in response:\n",
        "    print(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "431ae070",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate human-like text, answer questions, and even engage in conversation, making them a powerful tool for various applications such as language translation, text summarization, and chatbots.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.choices[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2d36bd6",
      "metadata": {},
      "source": [
        "## 4) Understanding `temperature`\n",
        "The **temperature** parameter adjusts the **randomness** of token sampling. Intuitively, the model produces a probability distribution over possible next tokens from its logits $z$. The temperature rescales those logits:\n",
        "\n",
        "$$p_i = \\mathrm{softmax}\\!\\left(\\frac{z_i}{T}\\right) = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}.$$\n",
        "\n",
        "- Lower $T$ (e.g. $T=0.2$): the distribution is *sharper* around high-probability tokens, yielding more **stable** outputs.\n",
        "- Higher $T$ (e.g. $T=0.8$): the distribution is *flatter*, encouraging **diversity** and sometimes creativity.\n",
        "\n",
        "**What this cell does:**\n",
        "- Sends the *same* prompt twice, once with `temperature=0.01` and once with `temperature=0.9`.\n",
        "- Prints both answers so you can compare tone and variability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a871a61b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Temperature: 0.01\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text based on the input it receives. LLMs are trained on vast amounts of text data, allowing them to learn patterns and relationships in language, and can be used for tasks such as language translation, text summarization, and conversation generation.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms and vast amounts of data to generate text, answer questions, and complete tasks. LLMs are trained on massive datasets of text from various sources, enabling them to learn patterns, relationships, and nuances of language, and generate human-like responses to a wide range of inputs and prompts.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within large datasets of text. By training on vast amounts of data, LLMs can generate human-like text, answer questions, and even engage in conversation, making them a powerful tool for applications such as language translation, text summarization, and chatbots.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate coherent and contextually relevant text, answer questions, and even engage in conversation, mimicking human-like language abilities.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms to learn patterns and relationships within vast amounts of text data. By training on massive datasets, LLMs can generate human-like text, answer questions, and even engage in conversation, making them a powerful tool for various applications such as language translation, text summarization, and chatbots.\n",
            "\n",
            "Temperature: 0.9\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, using complex algorithms and massive datasets to generate text, answer questions, and even converse with humans. LLMs are trained on vast amounts of text data, allowing them to learn patterns, relationships, and nuances of language, and generate coherent and contextually relevant responses to a wide range of queries and prompts.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, using complex algorithms to analyze and generate text based on vast amounts of training data. LLMs, like myself, can perform tasks such as answering questions, translating languages, and generating text, by recognizing patterns and relationships in language to provide helpful and informative responses.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, generating human-like text and responses based on the patterns and relationships it learns from vast amounts of data. LLMs use complex algorithms and massive datasets to learn the structures and nuances of language, enabling them to perform tasks such as language translation, text summarization, and conversation simulation.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language, typically trained on vast amounts of text data to generate human-like responses. LLMs use complex algorithms and neural networks to learn patterns and relationships in language, allowing them to perform tasks such as language translation, text summarization, and conversation generation.\n",
            "A Large Language Model (LLM) is a type of artificial intelligence designed to process and understand human language, trained on vast amounts of text data to generate human-like responses and answer questions. LLMs use complex algorithms and neural networks to learn patterns and relationships in language, enabling them to perform tasks such as language translation, text summarization, and conversation generation.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Describe the role of LLMs in academic research in one sentence.\"\n",
        "for temp in [0.01, 0.9]:\n",
        "    print()\n",
        "    print(\"Temperature:\", temp)\n",
        "    for i in range(5):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=prompt,\n",
        "            temperature=temp # lower temperature -> more deterministic\n",
        "        )\n",
        "        print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638df79e",
      "metadata": {},
      "source": [
        "## 5) Continuous Conversation (Keeping History)\n",
        "LLM APIs do **not** keep state between calls. To build a conversation, you keep a list of messages and send the *entire* recent history each time. We'll implement a small helper that:\n",
        "\n",
        "- Appends the user's message to a global `chat_history` list.\n",
        "- Calls the model with that history.\n",
        "- Appends the assistant's reply back into the history.\n",
        "- Returns the latest reply for display.\n",
        "\n",
        "We also keep the temperature low for focused answers. For longer chats, you can cap history to the last *k* turns to control token usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bfd8bf51",
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "\n",
        "def chat(user_input, temperature=0.2, max_turns=8):\n",
        "    \"\"\"Send one user turn and get a reply, preserving context.\n",
        "    - Keeps system prompt + last `max_turns` user/assistant messages.\n",
        "    \"\"\"\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Keep only the most recent `max_turns` pairs to control context size\n",
        "    system = chat_history[:1]\n",
        "    recent = chat_history[-(max_turns*2):] if len(chat_history) > 1 else []\n",
        "    window = system + recent\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=window,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    reply = resp.choices[0].message.content\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    return reply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1c533697",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "{'role': 'system', 'content': 'Tailor your answers for a bioinformatician.'}\n",
            "\n",
            "{'role': 'user', 'content': 'What is logistic regression?'}\n",
            "\n",
            "{'role': 'assistant', 'content': \"**Logistic Regression**\\n=======================\\n\\nLogistic regression is a statistical method used for binary classification problems, where the goal is to predict a binary outcome (0/1, yes/no, etc.) based on one or more predictor variables. It is a widely used technique in bioinformatics, particularly in the analysis of high-throughput data, such as gene expression or genomic variation.\\n\\n**Mathematical Formulation**\\n---------------------------\\n\\nLogistic regression models the probability of the positive class (e.g., disease presence) using a logistic function, also known as the sigmoid function:\\n\\np = 1 / (1 + e^(-z))\\n\\nwhere:\\n\\n* p is the probability of the positive class\\n* e is the base of the natural logarithm\\n* z is a linear combination of the predictor variables: z = β0 + β1*x1 + β2*x2 + … + βn\\\\*xn\\n\\nThe coefficients β0, β1, …, βn are estimated from the data using maximum likelihood estimation.\\n\\n**Key Concepts**\\n----------------\\n\\n* **Odds ratio**: The ratio of the odds of the positive class to the odds of the negative class. In logistic regression, the odds ratio is exponential in the coefficients (e^β).\\n* **Confusion matrix**: A table used to evaluate the performance of a classification model, including metrics such as accuracy, precision, recall, and F1 score.\\n* **Receiver operating characteristic (ROC) curve**: A plot of the true positive rate against the false positive rate at different thresholds, used to evaluate the model's ability to distinguish between classes.\\n\\n**Common Applications in Bioinformatics**\\n-----------------------------------------\\n\\n* **Gene expression analysis**: Logistic regression can be used to identify genes associated with a particular disease or phenotype.\\n* **Genomic variation analysis**: Logistic regression can be used to identify genetic variants associated with a particular trait or disease.\\n* **Protein function prediction**: Logistic regression can be used to predict the function of a protein based on its sequence or structural features.\\n\\n**Example Code in Python**\\n-------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Load data\\ndf = pd.read_csv('data.csv')\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\\n\\n# Train logistic regression model\\nmodel = LogisticRegression()\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions on test set\\ny_pred = model.predict(X_test)\\n\\n# Evaluate model performance\\nprint('Accuracy:', accuracy_score(y_test, y_pred))\\nprint('Classification Report:')\\nprint(classification_report(y_test, y_pred))\\nprint('Confusion Matrix:')\\nprint(confusion_matrix(y_test, y_pred))\\n```\\n\\nThis code trains a logistic regression model on a dataset, makes predictions on a test set, and evaluates the model's performance using accuracy, classification report, and confusion matrix.\"}\n",
            "\n",
            "{'role': 'user', 'content': 'How does it differ from linear regression?'}\n",
            "\n",
            "{'role': 'assistant', 'content': \"**Differences between Logistic Regression and Linear Regression**\\n=============================================================\\n\\nLogistic regression and linear regression are both supervised learning algorithms used for regression tasks. However, they differ in their approach, application, and output.\\n\\n**1. Output Variable**\\n--------------------\\n\\n* **Linear Regression**: The output variable is continuous, and the goal is to predict a numerical value.\\n* **Logistic Regression**: The output variable is binary (0/1, yes/no, etc.), and the goal is to predict the probability of the positive class.\\n\\n**2. Cost Function**\\n------------------\\n\\n* **Linear Regression**: The cost function is typically mean squared error (MSE) or mean absolute error (MAE), which measures the difference between predicted and actual values.\\n* **Logistic Regression**: The cost function is typically log loss or cross-entropy loss, which measures the difference between predicted probabilities and actual labels.\\n\\n**3. Activation Function**\\n----------------------\\n\\n* **Linear Regression**: No activation function is used, as the output is a linear combination of the input features.\\n* **Logistic Regression**: The sigmoid function (1 / (1 + e^(-z))) is used as the activation function to map the linear combination of input features to a probability between 0 and 1.\\n\\n**4. Interpretation of Coefficients**\\n----------------------------------\\n\\n* **Linear Regression**: The coefficients represent the change in the output variable for a one-unit change in the input feature, while holding all other features constant.\\n* **Logistic Regression**: The coefficients represent the change in the log-odds of the positive class for a one-unit change in the input feature, while holding all other features constant.\\n\\n**5. Assumptions**\\n----------------\\n\\n* **Linear Regression**: Assumes linearity, independence, homoscedasticity, normality, and no multicollinearity.\\n* **Logistic Regression**: Assumes independence, no multicollinearity, and a binary output variable.\\n\\n**Example Code in Python**\\n-------------------------\\n\\n```python\\nimport numpy as np\\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\\nimport matplotlib.pyplot as plt\\n\\n# Generate sample data\\nnp.random.seed(0)\\nX = np.random.rand(100, 1)\\ny_linear = 3 + 2 * X + np.random.randn(100, 1) / 1.5\\ny_logistic = (X > 0.5).astype(int)\\n\\n# Train linear regression model\\nmodel_linear = LinearRegression()\\nmodel_linear.fit(X, y_linear)\\n\\n# Train logistic regression model\\nmodel_logistic = LogisticRegression()\\nmodel_logistic.fit(X, y_logistic)\\n\\n# Plot data and regression lines\\nplt.figure(figsize=(12, 6))\\n\\nplt.subplot(1, 2, 1)\\nplt.scatter(X, y_linear)\\nplt.plot(X, model_linear.predict(X), color='red')\\nplt.title('Linear Regression')\\n\\nplt.subplot(1, 2, 2)\\nplt.scatter(X, y_logistic)\\nplt.plot(X, model_logistic.predict_proba(X)[:, 1], color='red')\\nplt.title('Logistic Regression')\\n\\nplt.show()\\n```\\n\\nThis code generates sample data, trains linear and logistic regression models, and plots the data with the regression lines. The linear regression model predicts a continuous output, while the logistic regression model predicts the probability of the positive class.\"}\n"
          ]
        }
      ],
      "source": [
        "chat_history = [\n",
        "    {\"role\": \"system\", \"content\": \"Tailor your answers for a bioinformatician.\"}\n",
        "]\n",
        "\n",
        "chat(\"What is logistic regression?\")\n",
        "chat(\"How does it differ from linear regression?\")\n",
        "\n",
        "for ch in chat_history:\n",
        "    print()\n",
        "    print(ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "867fad61",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "{'role': 'system', 'content': 'Tailor your answers for a bioinformatician.'}\n",
            "\n",
            "{'role': 'user', 'content': 'What is logistic regression?'}\n",
            "\n",
            "{'role': 'assistant', 'content': \"**Logistic Regression**\\n=======================\\n\\nLogistic regression is a statistical method used for binary classification problems, where the goal is to predict a binary outcome (0/1, yes/no, etc.) based on one or more predictor variables. It is a widely used technique in bioinformatics, particularly in the analysis of high-throughput data, such as gene expression or genomic variation.\\n\\n**Mathematical Formulation**\\n---------------------------\\n\\nLogistic regression models the probability of the positive class (e.g., disease presence) using a logistic function, also known as the sigmoid function:\\n\\np = 1 / (1 + e^(-z))\\n\\nwhere:\\n\\n* p is the probability of the positive class\\n* e is the base of the natural logarithm\\n* z is a linear combination of the predictor variables: z = β0 + β1*x1 + β2*x2 + … + βn\\\\*xn\\n\\nThe coefficients β0, β1, …, βn are estimated from the data using maximum likelihood estimation.\\n\\n**Key Concepts**\\n----------------\\n\\n* **Odds ratio**: The ratio of the odds of the positive class to the odds of the negative class. In logistic regression, the odds ratio is exponential in the coefficients (e^β).\\n* **Confusion matrix**: A table used to evaluate the performance of a classification model, including metrics such as accuracy, precision, recall, and F1 score.\\n* **Receiver operating characteristic (ROC) curve**: A plot of the true positive rate against the false positive rate at different thresholds, used to evaluate the model's ability to distinguish between classes.\\n\\n**Common Applications in Bioinformatics**\\n-----------------------------------------\\n\\n* **Gene expression analysis**: Logistic regression can be used to identify genes associated with a particular disease or phenotype.\\n* **Genomic variation analysis**: Logistic regression can be used to identify genetic variants associated with a particular trait or disease.\\n* **Protein function prediction**: Logistic regression can be used to predict the function of a protein based on its sequence or structural features.\\n\\n**Example Code in Python**\\n-------------------------\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\\n# Load data\\ndf = pd.read_csv('data.csv')\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)\\n\\n# Train logistic regression model\\nmodel = LogisticRegression()\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions on test set\\ny_pred = model.predict(X_test)\\n\\n# Evaluate model performance\\nprint('Accuracy:', accuracy_score(y_test, y_pred))\\nprint('Classification Report:')\\nprint(classification_report(y_test, y_pred))\\nprint('Confusion Matrix:')\\nprint(confusion_matrix(y_test, y_pred))\\n```\\n\\nThis code trains a logistic regression model on a dataset, makes predictions on a test set, and evaluates the model's performance using accuracy, classification report, and confusion matrix.\"}\n",
            "\n",
            "{'role': 'user', 'content': 'How does it differ from linear regression?'}\n",
            "\n",
            "{'role': 'assistant', 'content': \"**Differences between Logistic Regression and Linear Regression**\\n=============================================================\\n\\nLogistic regression and linear regression are both supervised learning algorithms used for regression tasks. However, they differ in their approach, application, and output.\\n\\n**1. Output Variable**\\n--------------------\\n\\n* **Linear Regression**: The output variable is continuous, and the goal is to predict a numerical value.\\n* **Logistic Regression**: The output variable is binary (0/1, yes/no, etc.), and the goal is to predict the probability of the positive class.\\n\\n**2. Cost Function**\\n------------------\\n\\n* **Linear Regression**: The cost function is typically mean squared error (MSE) or mean absolute error (MAE), which measures the difference between predicted and actual values.\\n* **Logistic Regression**: The cost function is typically log loss or cross-entropy loss, which measures the difference between predicted probabilities and actual labels.\\n\\n**3. Activation Function**\\n----------------------\\n\\n* **Linear Regression**: No activation function is used, as the output is a linear combination of the input features.\\n* **Logistic Regression**: The sigmoid function (1 / (1 + e^(-z))) is used as the activation function to map the linear combination of input features to a probability between 0 and 1.\\n\\n**4. Interpretation of Coefficients**\\n----------------------------------\\n\\n* **Linear Regression**: The coefficients represent the change in the output variable for a one-unit change in the input feature, while holding all other features constant.\\n* **Logistic Regression**: The coefficients represent the change in the log-odds of the positive class for a one-unit change in the input feature, while holding all other features constant.\\n\\n**5. Assumptions**\\n----------------\\n\\n* **Linear Regression**: Assumes linearity, independence, homoscedasticity, normality, and no multicollinearity.\\n* **Logistic Regression**: Assumes independence, no multicollinearity, and a binary output variable.\\n\\n**Example Code in Python**\\n-------------------------\\n\\n```python\\nimport numpy as np\\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\\nimport matplotlib.pyplot as plt\\n\\n# Generate sample data\\nnp.random.seed(0)\\nX = np.random.rand(100, 1)\\ny_linear = 3 + 2 * X + np.random.randn(100, 1) / 1.5\\ny_logistic = (X > 0.5).astype(int)\\n\\n# Train linear regression model\\nmodel_linear = LinearRegression()\\nmodel_linear.fit(X, y_linear)\\n\\n# Train logistic regression model\\nmodel_logistic = LogisticRegression()\\nmodel_logistic.fit(X, y_logistic)\\n\\n# Plot data and regression lines\\nplt.figure(figsize=(12, 6))\\n\\nplt.subplot(1, 2, 1)\\nplt.scatter(X, y_linear)\\nplt.plot(X, model_linear.predict(X), color='red')\\nplt.title('Linear Regression')\\n\\nplt.subplot(1, 2, 2)\\nplt.scatter(X, y_logistic)\\nplt.plot(X, model_logistic.predict_proba(X)[:, 1], color='red')\\nplt.title('Logistic Regression')\\n\\nplt.show()\\n```\\n\\nThis code generates sample data, trains linear and logistic regression models, and plots the data with the regression lines. The linear regression model predicts a continuous output, while the logistic regression model predicts the probability of the positive class.\"}\n",
            "\n",
            "{'role': 'user', 'content': 'what are some other classification methods?'}\n",
            "\n",
            "{'role': 'assistant', 'content': '**Other Classification Methods**\\n=============================\\n\\nBesides logistic regression, there are many other classification methods used in machine learning and bioinformatics. Here are some popular ones:\\n\\n### 1. **Decision Trees**\\n\\n* **Description**: A decision tree is a tree-like model that splits the data into subsets based on the features.\\n* **Advantages**: Easy to interpret, handles categorical features, and can handle missing values.\\n* **Disadvantages**: Can be prone to overfitting, and the tree can become complex.\\n\\n### 2. **Random Forests**\\n\\n* **Description**: An ensemble method that combines multiple decision trees to improve the accuracy and robustness of the model.\\n* **Advantages**: Handles high-dimensional data, reduces overfitting, and improves accuracy.\\n* **Disadvantages**: Can be computationally expensive, and the model can be difficult to interpret.\\n\\n### 3. **Support Vector Machines (SVMs)**\\n\\n* **Description**: A method that finds the hyperplane that maximally separates the classes in the feature space.\\n* **Advantages**: Handles high-dimensional data, robust to noise, and can handle non-linear relationships.\\n* **Disadvantages**: Can be computationally expensive, and the model can be difficult to interpret.\\n\\n### 4. **K-Nearest Neighbors (KNN)**\\n\\n* **Description**: A method that assigns a new sample to the class of the majority of its k-nearest neighbors.\\n* **Advantages**: Simple to implement, handles non-linear relationships, and can handle high-dimensional data.\\n* **Disadvantages**: Can be computationally expensive, and the choice of k can be critical.\\n\\n### 5. **Naive Bayes**\\n\\n* **Description**: A method that assumes independence between features and calculates the probability of a sample belonging to a class based on Bayes\\' theorem.\\n* **Advantages**: Simple to implement, handles high-dimensional data, and can handle missing values.\\n* **Disadvantages**: Can be sensitive to the choice of prior probabilities, and the independence assumption can be violated.\\n\\n### 6. **Gradient Boosting**\\n\\n* **Description**: An ensemble method that combines multiple weak models to create a strong predictive model.\\n* **Advantages**: Handles high-dimensional data, reduces overfitting, and improves accuracy.\\n* **Disadvantages**: Can be computationally expensive, and the model can be difficult to interpret.\\n\\n### 7. **Neural Networks**\\n\\n* **Description**: A method that uses artificial neural networks to learn complex relationships between features and classes.\\n* **Advantages**: Can handle high-dimensional data, non-linear relationships, and can learn complex patterns.\\n* **Disadvantages**: Can be computationally expensive, and the model can be difficult to interpret.\\n\\n**Example Code in Python**\\n-------------------------\\n\\n```python\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.neural_network import MLPClassifier\\nfrom sklearn.metrics import accuracy_score\\n\\n# Load iris dataset\\niris = load_iris()\\nX = iris.data\\ny = iris.target\\n\\n# Split data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Train decision tree classifier\\ndt = DecisionTreeClassifier()\\ndt.fit(X_train, y_train)\\nprint(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt.predict(X_test)))\\n\\n# Train random forest classifier\\nrf = RandomForestClassifier()\\nrf.fit(X_train, y_train)\\nprint(\"Random Forest Accuracy:\", accuracy_score(y_test, rf.predict(X_test)))\\n\\n# Train SVM classifier\\nsvm = SVC()\\nsvm.fit(X_train, y_train)\\nprint(\"SVM Accuracy:\", accuracy_score(y_test, svm.predict(X_test)))\\n\\n# Train KNN classifier\\nknn = KNeighborsClassifier()\\nknn.fit(X_train, y_train)\\nprint(\"KNN Accuracy:\", accuracy_score(y_test, knn.predict(X_test)))\\n\\n# Train Naive Bayes classifier\\nnb = GaussianNB()\\nnb.fit(X_train, y_train)\\nprint(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb.predict(X_test)))\\n\\n# Train Gradient Boosting classifier\\ngb = GradientBoostingClassifier()\\ngb.fit(X_train, y_train)\\nprint(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb.predict(X_test)))\\n\\n# Train Neural Network classifier\\nnn = MLPClassifier()\\nnn.fit(X_train, y_train)\\nprint(\"Neural Network Accuracy:\", accuracy_score(y_test, nn.predict(X_test)))\\n```\\n\\nThis code trains different classification models on the iris dataset and prints their accuracy on the test set.'}\n"
          ]
        }
      ],
      "source": [
        "chat(\"what are some other classification methods?\")\n",
        "\n",
        "for ch in chat_history:\n",
        "    print()\n",
        "    print(ch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a049e835",
      "metadata": {},
      "source": [
        "## 8) Exercise — Your First Prompt\n",
        "Try your own research-related prompts. A few ideas:\n",
        "\n",
        "1. Summarise your current project in **one paragraph**.\n",
        "2. Ask for **three open research questions** in your field.\n",
        "3. Request a **draft methods paragraph** describing your dataset and analysis steps.\n",
        "\n",
        "Remember you can tweak `temperature` to trade off consistency vs creativity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "36d1cda6",
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_history = [\n",
        "    {\"role\": \"system\", \"content\": \"Tailor your answers for a bioinformatician.\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "58ace76d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As a bioinformatician, you're likely familiar with complex systems and data-driven approaches. Renewable energy policy research presents several challenges that can be broken down into the following categories:\n",
            "\n",
            "1. **Integration and Interoperability**: Renewable energy sources, such as solar and wind power, have variable output, making it challenging to integrate them into existing energy grids. This requires advanced forecasting and grid management systems to ensure a stable and reliable energy supply.\n",
            "2. **Data Quality and Availability**: High-quality data on energy production, consumption, and grid operations is essential for informed policy decisions. However, data gaps, inconsistencies, and lack of standardization can hinder research and policy development.\n",
            "3. **Complexity and Uncertainty**: Renewable energy systems involve complex interactions between technological, economic, social, and environmental factors. Uncertainties, such as future energy demand, technology costs, and policy frameworks, can make it difficult to predict the effectiveness of different policy interventions.\n",
            "4. **Spatial and Temporal Scales**: Renewable energy policy research must consider multiple spatial scales (e.g., local, regional, national) and temporal scales (e.g., short-term, long-term). This requires balancing competing priorities, such as energy security, economic development, and environmental protection.\n",
            "5. **Stakeholder Engagement and Social Acceptance**: Effective policy development requires engagement with diverse stakeholders, including industry, government, civil society, and local communities. Social acceptance of renewable energy technologies and infrastructure can be a significant challenge, particularly if it involves land use changes or community disruption.\n",
            "6. **Economic and Financial Challenges**: Renewable energy technologies can be capital-intensive, and their economic viability often depends on policy support, such as tax incentives, subsidies, or carbon pricing. Fluctuations in energy markets, technology costs, and policy frameworks can create uncertainty and affect investment decisions.\n",
            "7. **Policy Frameworks and Governance**: Renewable energy policy research must navigate complex governance structures, including international agreements, national policies, and regional regulations. Effective policy frameworks require coordination, consistency, and adaptability to address the dynamic nature of the energy sector.\n",
            "8. **Technology and Innovation**: The rapid evolution of renewable energy technologies, such as solar panels and wind turbines, creates opportunities for improved efficiency and reduced costs. However, it also poses challenges for policy development, as technologies may become outdated or new ones may emerge, requiring updates to policy frameworks.\n",
            "9. **Environmental and Social Impacts**: Renewable energy technologies can have environmental and social implications, such as land use changes, water usage, or community displacement. Policy research must consider these impacts and develop strategies to mitigate them.\n",
            "10. **Scalability and Replicability**: Renewable energy policy research must be scalable and replicable across different contexts, including developed and developing countries, to ensure widespread adoption and maximize global benefits.\n",
            "\n",
            "By acknowledging these challenges, researchers and policymakers can develop more effective strategies to address the complexities of renewable energy policy research and create a more sustainable energy future. As a bioinformatician, you can apply your expertise in data analysis, modeling, and computational methods to help tackle these challenges and contribute to the development of evidence-based renewable energy policies.\n"
          ]
        }
      ],
      "source": [
        "# Example: replace with your own question(s)\n",
        "question = \"Summarise the challenges in renewable energy policy research.\"\n",
        "print(chat(question))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Wrap-Up & Next Steps\n",
        "- You configured an OpenAI-compatible client to talk to **Groq**.\n",
        "- You sent your first prompts using **Llama-3 70B** and explored the impact of `temperature`.\n",
        "- You kept conversation state locally in a Python list and learned how to save it.\n",
        "\n",
        "**Key terms:** tokens, temperature, logits, softmax, stateless API, chat history.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
